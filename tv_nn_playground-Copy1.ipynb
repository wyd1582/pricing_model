{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>17.8441415139561</th>\n",
       "      <th>20.8345047623369</th>\n",
       "      <th>9.75006668486477</th>\n",
       "      <th>21.9059403329483</th>\n",
       "      <th>0.8940934127987</th>\n",
       "      <th>19.2655031401848</th>\n",
       "      <th>24.7296107833937</th>\n",
       "      <th>23.8037970237158</th>\n",
       "      <th>20.2116397220013</th>\n",
       "      <th>...</th>\n",
       "      <th>40.0881646175074</th>\n",
       "      <th>23.5263868530805</th>\n",
       "      <th>28.7622014146842</th>\n",
       "      <th>11.0581663341492</th>\n",
       "      <th>11.5397875284751</th>\n",
       "      <th>31.1640774750065</th>\n",
       "      <th>19.6980902784894</th>\n",
       "      <th>11.8289904620517</th>\n",
       "      <th>21.4887755338747</th>\n",
       "      <th>30.696271484106</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <td>17.844142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.431551</td>\n",
       "      <td>14.944885</td>\n",
       "      <td>12.706567</td>\n",
       "      <td>17.821728</td>\n",
       "      <td>26.259722</td>\n",
       "      <td>30.495361</td>\n",
       "      <td>15.754598</td>\n",
       "      <td>26.961524</td>\n",
       "      <td>...</td>\n",
       "      <td>35.897737</td>\n",
       "      <td>15.332237</td>\n",
       "      <td>22.557722</td>\n",
       "      <td>14.004654</td>\n",
       "      <td>13.610536</td>\n",
       "      <td>25.549684</td>\n",
       "      <td>8.342744</td>\n",
       "      <td>13.359954</td>\n",
       "      <td>11.973057</td>\n",
       "      <td>24.976943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>20.834505</td>\n",
       "      <td>27.431551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.003052</td>\n",
       "      <td>30.231553</td>\n",
       "      <td>20.853681</td>\n",
       "      <td>7.932022</td>\n",
       "      <td>13.322052</td>\n",
       "      <td>31.633801</td>\n",
       "      <td>5.056304</td>\n",
       "      <td>...</td>\n",
       "      <td>45.178950</td>\n",
       "      <td>31.425586</td>\n",
       "      <td>35.515360</td>\n",
       "      <td>23.587277</td>\n",
       "      <td>23.816870</td>\n",
       "      <td>37.487015</td>\n",
       "      <td>28.672135</td>\n",
       "      <td>23.958331</td>\n",
       "      <td>29.930654</td>\n",
       "      <td>37.099025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>9.750067</td>\n",
       "      <td>14.944885</td>\n",
       "      <td>23.003052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.616483</td>\n",
       "      <td>9.708985</td>\n",
       "      <td>21.592207</td>\n",
       "      <td>26.582277</td>\n",
       "      <td>21.715362</td>\n",
       "      <td>22.440459</td>\n",
       "      <td>...</td>\n",
       "      <td>38.884407</td>\n",
       "      <td>21.410910</td>\n",
       "      <td>27.059202</td>\n",
       "      <td>5.217206</td>\n",
       "      <td>6.172754</td>\n",
       "      <td>29.599593</td>\n",
       "      <td>17.115810</td>\n",
       "      <td>6.697852</td>\n",
       "      <td>19.149508</td>\n",
       "      <td>29.106654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>21.905940</td>\n",
       "      <td>12.706567</td>\n",
       "      <td>30.231553</td>\n",
       "      <td>19.616483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.887686</td>\n",
       "      <td>29.172416</td>\n",
       "      <td>33.036705</td>\n",
       "      <td>9.313997</td>\n",
       "      <td>29.805714</td>\n",
       "      <td>...</td>\n",
       "      <td>33.573661</td>\n",
       "      <td>8.580248</td>\n",
       "      <td>18.638509</td>\n",
       "      <td>18.909976</td>\n",
       "      <td>18.619977</td>\n",
       "      <td>22.165954</td>\n",
       "      <td>9.584125</td>\n",
       "      <td>18.437603</td>\n",
       "      <td>4.254732</td>\n",
       "      <td>21.503276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.894093</td>\n",
       "      <td>17.821728</td>\n",
       "      <td>20.853681</td>\n",
       "      <td>9.708985</td>\n",
       "      <td>21.887686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.286239</td>\n",
       "      <td>24.745768</td>\n",
       "      <td>23.787000</td>\n",
       "      <td>20.231406</td>\n",
       "      <td>...</td>\n",
       "      <td>40.078193</td>\n",
       "      <td>23.509391</td>\n",
       "      <td>28.748301</td>\n",
       "      <td>11.021962</td>\n",
       "      <td>11.505099</td>\n",
       "      <td>31.151249</td>\n",
       "      <td>19.677788</td>\n",
       "      <td>11.795152</td>\n",
       "      <td>21.470167</td>\n",
       "      <td>30.683248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0.000000   17.844142  20.834505  9.750067   21.905940  0.894093   \\\n",
       "NaN NaN  17.844142   0.000000  27.431551  14.944885  12.706567  17.821728   \n",
       "    NaN  20.834505  27.431551   0.000000  23.003052  30.231553  20.853681   \n",
       "    NaN   9.750067  14.944885  23.003052   0.000000  19.616483   9.708985   \n",
       "    NaN  21.905940  12.706567  30.231553  19.616483   0.000000  21.887686   \n",
       "    NaN   0.894093  17.821728  20.853681   9.708985  21.887686   0.000000   \n",
       "\n",
       "         19.265503  24.729611  23.803797  20.211640    ...      40.088165  \\\n",
       "NaN NaN  26.259722  30.495361  15.754598  26.961524    ...      35.897737   \n",
       "    NaN   7.932022  13.322052  31.633801   5.056304    ...      45.178950   \n",
       "    NaN  21.592207  26.582277  21.715362  22.440459    ...      38.884407   \n",
       "    NaN  29.172416  33.036705   9.313997  29.805714    ...      33.573661   \n",
       "    NaN  19.286239  24.745768  23.787000  20.231406    ...      40.078193   \n",
       "\n",
       "         23.526387  28.762201  11.058166  11.539788  31.164077  19.698090  \\\n",
       "NaN NaN  15.332237  22.557722  14.004654  13.610536  25.549684   8.342744   \n",
       "    NaN  31.425586  35.515360  23.587277  23.816870  37.487015  28.672135   \n",
       "    NaN  21.410910  27.059202   5.217206   6.172754  29.599593  17.115810   \n",
       "    NaN   8.580248  18.638509  18.909976  18.619977  22.165954   9.584125   \n",
       "    NaN  23.509391  28.748301  11.021962  11.505099  31.151249  19.677788   \n",
       "\n",
       "         11.828990  21.488776  30.696271  \n",
       "NaN NaN  13.359954  11.973057  24.976943  \n",
       "    NaN  23.958331  29.930654  37.099025  \n",
       "    NaN   6.697852  19.149508  29.106654  \n",
       "    NaN  18.437603   4.254732  21.503276  \n",
       "    NaN  11.795152  21.470167  30.683248  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#translate from the matlab code\n",
    "import xlrd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "NumSKU=49\n",
    "NumVar=13\n",
    "ID=[1138263,1139362,1139363,1141061,1142731,1143640,1144140,\n",
    "        1148001,1148010,1148081,1162466,1162467,1162557,1162558,\n",
    "        1162559,1163152,1163153,1164313,1164961,1164962,1165757,\n",
    "        1166153,1166984,1166998,1167021,1167087,1167847,1167918,\n",
    "        1170236,1170372,1170739,1173299,1174241,1174242,1174243,\n",
    "        1174244,1174275,1174293,1174299,1174313,1174314,1174315,\n",
    "        1174339,1174340,1175687,1175833,1175835,1175950,1177151]\n",
    "tv_info = pd.read_excel('Television.xlsx', sheet_name='Main')\n",
    "tv_info.head()\n",
    "\n",
    "tv_sim = pd.read_excel('Television.xlsx', sheet_name='Similarity')\n",
    "tv_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>SalesQuantity</th>\n",
       "      <th>SalesQuantityLag1</th>\n",
       "      <th>SalesQuantityLag7</th>\n",
       "      <th>SalesQuantityLag14</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>InventoryAvailability</th>\n",
       "      <th>WeekOfYear</th>\n",
       "      <th>...</th>\n",
       "      <th>Var75</th>\n",
       "      <th>Var76</th>\n",
       "      <th>Var77</th>\n",
       "      <th>Var78</th>\n",
       "      <th>Var79</th>\n",
       "      <th>Var80</th>\n",
       "      <th>Var81</th>\n",
       "      <th>Var82</th>\n",
       "      <th>Var83</th>\n",
       "      <th>Var84</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2626.27000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1779.66000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2329.659900</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2533.055050</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2541.530000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1753.387550</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2651.69398</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1880.51008</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2365.113317</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2555.651667</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2794.132285</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1842.372600</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2774.57500</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1851.69608</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2355.083980</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2725.285017</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2835.449192</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1789.243869</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2795.76000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1876.27505</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2468.837450</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2965.260000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2721.716275</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1905.935100</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2795.76000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1876.27505</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2468.837450</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2626.273333</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3473.720000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1905.925200</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       Date  SalesQuantity  SalesQuantityLag1  SalesQuantityLag7  \\\n",
       "0   1 2016-01-01              2                  1                  1   \n",
       "1   1 2016-01-02              6                  2                  1   \n",
       "2   1 2016-01-03              5                  6                  1   \n",
       "3   1 2016-01-04              6                  5                  1   \n",
       "4   1 2016-01-05              2                  6                  1   \n",
       "\n",
       "   SalesQuantityLag14       Price  Discount  InventoryAvailability  \\\n",
       "0                   1  2626.27000      1.01                   0.93   \n",
       "1                   1  2651.69398      1.01                   0.93   \n",
       "2                   1  2774.57500      1.01                   0.93   \n",
       "3                   1  2795.76000      1.01                   0.93   \n",
       "4                   1  2795.76000      1.01                   0.93   \n",
       "\n",
       "   WeekOfYear  ...         Var75  Var76        Var77  Var78        Var79  \\\n",
       "0           1  ...    1779.66000   1.01  2329.659900   1.01  2533.055050   \n",
       "1           1  ...    1880.51008   1.01  2365.113317   1.01  2555.651667   \n",
       "2           1  ...    1851.69608   1.01  2355.083980   1.01  2725.285017   \n",
       "3           2  ...    1876.27505   1.01  2468.837450   1.01  2965.260000   \n",
       "4           2  ...    1876.27505   1.01  2468.837450   1.01  2626.273333   \n",
       "\n",
       "   Var80        Var81  Var82        Var83  Var84  \n",
       "0   1.01  2541.530000   1.01  1753.387550   1.01  \n",
       "1   1.01  2794.132285   1.01  1842.372600   1.01  \n",
       "2   1.01  2835.449192   1.01  1789.243869   1.01  \n",
       "3   1.01  2721.716275   1.01  1905.935100   1.01  \n",
       "4   1.01  3473.720000   1.01  1905.925200   1.01  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tv_info = pd.read_excel('C:/Users/wyd15/Downloads/Television.xlsx', sheet_name='new_tv_info') #processed by matlab\n",
    "new_tv_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural network train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import libraries and packages\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "#translate from the matlab code\n",
    "import xlrd\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import InputLayer, Input\n",
    "from tensorflow.python.keras.layers import Reshape, MaxPooling2D\n",
    "from tensorflow.python.keras.layers import Conv2D, Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "#train data\n",
    "new_tv_info = pd.read_excel('C:/Users/wyd15/Downloads/Television.xlsx', sheet_name='new_tv_info') #processed by matlab\n",
    "tv_sim = pd.read_excel('Television.xlsx', sheet_name='Similarity')\n",
    "#tv_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24697\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>SalesQuantity</th>\n",
       "      <th>SalesQuantityLag1</th>\n",
       "      <th>SalesQuantityLag7</th>\n",
       "      <th>SalesQuantityLag14</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>InventoryAvailability</th>\n",
       "      <th>WeekOfYear</th>\n",
       "      <th>...</th>\n",
       "      <th>Var75</th>\n",
       "      <th>Var76</th>\n",
       "      <th>Var77</th>\n",
       "      <th>Var78</th>\n",
       "      <th>Var79</th>\n",
       "      <th>Var80</th>\n",
       "      <th>Var81</th>\n",
       "      <th>Var82</th>\n",
       "      <th>Var83</th>\n",
       "      <th>Var84</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2626.27000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1779.66000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2329.659900</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2533.055050</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2541.530000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1753.387550</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2651.69398</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1880.51008</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2365.113317</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2555.651667</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2794.132285</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1842.372600</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2774.57500</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1851.69608</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2355.083980</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2725.285017</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2835.449192</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1789.243869</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2795.76000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1876.27505</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2468.837450</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2965.260000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2721.716275</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1905.935100</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2795.76000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1876.27505</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2468.837450</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2626.273333</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3473.720000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1905.925200</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       Date  SalesQuantity  SalesQuantityLag1  SalesQuantityLag7  \\\n",
       "0   1 2016-01-01              2                  1                  1   \n",
       "1   1 2016-01-02              6                  2                  1   \n",
       "2   1 2016-01-03              5                  6                  1   \n",
       "3   1 2016-01-04              6                  5                  1   \n",
       "4   1 2016-01-05              2                  6                  1   \n",
       "\n",
       "   SalesQuantityLag14       Price  Discount  InventoryAvailability  \\\n",
       "0                   1  2626.27000      1.01                   0.93   \n",
       "1                   1  2651.69398      1.01                   0.93   \n",
       "2                   1  2774.57500      1.01                   0.93   \n",
       "3                   1  2795.76000      1.01                   0.93   \n",
       "4                   1  2795.76000      1.01                   0.93   \n",
       "\n",
       "   WeekOfYear  ...         Var75  Var76        Var77  Var78        Var79  \\\n",
       "0           1  ...    1779.66000   1.01  2329.659900   1.01  2533.055050   \n",
       "1           1  ...    1880.51008   1.01  2365.113317   1.01  2555.651667   \n",
       "2           1  ...    1851.69608   1.01  2355.083980   1.01  2725.285017   \n",
       "3           2  ...    1876.27505   1.01  2468.837450   1.01  2965.260000   \n",
       "4           2  ...    1876.27505   1.01  2468.837450   1.01  2626.273333   \n",
       "\n",
       "   Var80        Var81  Var82        Var83  Var84  \n",
       "0   1.01  2541.530000   1.01  1753.387550   1.01  \n",
       "1   1.01  2794.132285   1.01  1842.372600   1.01  \n",
       "2   1.01  2835.449192   1.01  1789.243869   1.01  \n",
       "3   1.01  2721.716275   1.01  1905.935100   1.01  \n",
       "4   1.01  3473.720000   1.01  1905.925200   1.01  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(new_tv_info))\n",
    "new_tv_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0, train_loss: 790129.125000, test_loss: 86971.968750\n",
      "iter: 100, train_loss: 61.847450, test_loss: 2908.143066\n",
      "iter: 200, train_loss: 28.520618, test_loss: 768.545105\n",
      "iter: 300, train_loss: 30.584072, test_loss: 317.906342\n",
      "iter: 400, train_loss: 0.296206, test_loss: 0.626445\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_placeholder(input1_dim=18, input2_dim=61):\n",
    "    return tf.placeholder(shape=(None, input1_dim), dtype=tf.float32), \\\n",
    "           tf.placeholder(shape=(None, input2_dim), dtype=tf.float32), \\\n",
    "           tf.placeholder(shape=(None, ), dtype=tf.float32)\n",
    "\n",
    "\n",
    "def get_output(input1, input2):\n",
    "     \n",
    "    input1_dim = input1.get_shape()[1]\n",
    "    input2_dim = input2.get_shape()[1]\n",
    "    W1_1 = tf.get_variable('W1_1', shape=(input1_dim, input1_dim+input2_dim))\n",
    "    W1_2 = tf.get_variable('W1_2', shape=(input2_dim, input1_dim+input2_dim))\n",
    "    b1 = tf.get_variable('b1', shape=(1, input1_dim+input2_dim))\n",
    "    \n",
    "    o1_1 = tf.matmul(input1, W1_1)\n",
    "    o1_2 = tf.matmul(input2, W1_2)\n",
    "    o1 = o1_1 + o1_2 + b1\n",
    "    o1 = tf.nn.sigmoid(o1)\n",
    "\n",
    "    W2_1 = tf.get_variable('W2_1', shape=(input2_dim, 1))\n",
    "    W2_2 = tf.get_variable('W2_2', shape=(input1_dim+input2_dim, 1))\n",
    "    b2 = tf.get_variable('b2', shape=(1, 1))\n",
    "    o2_1 = tf.matmul(input2, W2_1)\n",
    "    o2_2 = tf.matmul(o1, W2_2)\n",
    "    o2 = o2_1 + o2_2 + b2\n",
    "    o2 = tf.reshape(o2, (-1, ))\n",
    "    \n",
    "    saver = tf.train.Saver([W1_1, W1_2, b1, W2_1, W2_2, b2])\n",
    "    Vars=[W1_1, W1_2, b1, W2_1, W2_2, b2]\n",
    "    \n",
    "    return o2, saver, Vars\n",
    "\n",
    "\n",
    "def get_loss(labels, predictions):\n",
    "    return tf.losses.mean_squared_error(labels, predictions)\n",
    "\n",
    "\n",
    "def main():\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    batch_size = 50\n",
    "    learning_rate = 0.11\n",
    "    tf.reset_default_graph()\n",
    "    x1, x2, y = get_placeholder(18, 61)\n",
    "    output, saver, Vars = get_output(x1, x2)\n",
    "\n",
    "    loss = get_loss(y, output)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    #train-test_splie\n",
    "    msk = np.random.rand(len(new_tv_info)) < 0.85\n",
    "    tv_train = new_tv_info[msk]\n",
    "    tv_test = new_tv_info[~msk]\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for step in range(493):\n",
    "            x1_train = tv_train.iloc[step:step+batch_size, 66:84].values \n",
    "            x2_train = np.concatenate((tv_train.iloc[step:step+batch_size, 3:11].values, tv_train.iloc[step:step+batch_size, 14:67].values), 1) \n",
    "            y_train = tv_train.iloc[step:step+batch_size, 2].values \n",
    "            \n",
    "            x1_test = tv_test.iloc[step:step+batch_size, 66:84].values \n",
    "            x2_test = np.concatenate((tv_test.iloc[step:step+batch_size, 3:11].values, tv_test.iloc[step:step+batch_size, 14:67].values), 1) \n",
    "            y_test = tv_test.iloc[step:step+batch_size, 2].values \n",
    "            \n",
    "            _train_loss, _ = sess.run([loss, train_op],\n",
    "                                   feed_dict={x1: x1_train,\n",
    "                                              x2: x2_train,\n",
    "                                              y: y_train})\n",
    "            \n",
    "            _test_loss= sess.run([loss],\n",
    "                                   feed_dict={x1: x1_test,\n",
    "                                              x2: x2_test,\n",
    "                                              y: y_test})\n",
    "            \n",
    "            #results, _ = sess.run([output]) #print parameters, W1_1 etc..\n",
    "            \n",
    "            if step % 100==0:\n",
    "                saver.save(sess, 'C:/Users/wyd15/Desktop/tv_model/tv_modelslack.ckpt', global_step=step)\n",
    "                print(\"iter: %d, train_loss: %f, test_loss: %f\"%(step, _train_loss,  _test_loss[0]))\n",
    "                #print('output:', )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:0, train_loss: 387154.093750, test_loss: 2670.869629\n",
      "test prediction parameters results: [array([ 75.87928772,  65.21278381,  55.27078629,  58.219944  ,\n",
      "        65.50083923,  62.80655289,  63.06184769,  51.526371  ,\n",
      "        49.79753494,  53.8701973 ,  56.84691238,  74.79963684,\n",
      "        61.30699158,  56.17599487,  45.11227417,  51.51878738,\n",
      "        43.78727341,  42.5931015 ,  57.85210037,  53.92779922,\n",
      "        55.53042984,  61.38663101,  55.4371376 ,  59.43503189,\n",
      "        57.33987808,  56.95289993,  57.04330826,  62.09218216,\n",
      "        56.30978394,  56.17868042,  63.40144348,  62.89990616,\n",
      "        37.52988052,  38.19394302,  61.99638748,  37.03100967,\n",
      "        36.73166275,  49.18375397,  46.22643661,  32.58309555,\n",
      "        32.4204216 ,  32.52098465,  63.98768234,  64.22125244,\n",
      "        64.06978607,  64.32680511,  64.23438263,  64.13961029,\n",
      "        64.39714813,  64.05422974], dtype=float32)]\n",
      "iter:100, train_loss: 72.489128, test_loss: 5114.185059\n",
      "test prediction parameters results: [array([ -9.29467850e+01,  -1.13043106e+02,  -9.64898987e+01,\n",
      "        -8.51466599e+01,  -1.01293991e+02,  -1.01787178e+02,\n",
      "        -1.01119888e+02,  -1.01140938e+02,  -1.00355583e+02,\n",
      "        -9.96641998e+01,  -1.09477051e+02,  -1.09302948e+02,\n",
      "        -1.09816849e+02,  -1.08831421e+02,  -1.09097572e+02,\n",
      "        -1.08867073e+02,  -1.08428154e+02,  -1.08887955e+02,\n",
      "        -1.08519981e+02,  -1.08027863e+02,  -1.08598091e+02,\n",
      "        -1.08367645e+02,  -1.23325386e+01,  -5.26970434e+00,\n",
      "         3.26803064e+00,  -5.29083776e+00,   9.75400734e+00,\n",
      "         4.58790874e+00,  -1.00427608e+01,  -7.15459204e+00,\n",
      "        -2.96243401e+01,   7.83017159e+00,   2.45643091e+00,\n",
      "        -2.74667883e+00,  -3.54888380e-01,  -4.29374790e+00,\n",
      "        -5.53133869e+00,  -1.13860903e+01,  -2.56315575e+01,\n",
      "        -2.65745964e+01,  -2.29370232e+01,  -1.20304012e+01,\n",
      "        -1.96615810e+01,  -2.85771084e+01,  -2.80239162e+01,\n",
      "        -1.76924744e+01,   1.55904627e+00,   3.13529444e+00,\n",
      "        -1.65762454e-02,  -1.08652706e+01], dtype=float32)]\n",
      "iter:200, train_loss: 46.008579, test_loss: 614.895020\n",
      "test prediction parameters results: [array([-55.22853088, -55.81244278, -56.85662842, -56.86396027,\n",
      "       -55.80954742, -55.79956055, -55.93818665,   7.45238161,\n",
      "         7.52100801,   7.8257947 ,   7.89442873,   7.09101534,\n",
      "         8.03168106,   8.2272768 ,   8.09126759,  -5.06623411,\n",
      "        -4.18448973,  -2.57403922,  -3.58089805,  -4.51126432,\n",
      "       -13.53684521,  -4.2325778 , -17.98591995, -17.54388046,\n",
      "       -17.78003311, -17.54518509, -17.71140671,   8.88885975,\n",
      "        16.17218399,  22.60207748,  24.32943344,  14.50481129,\n",
      "        25.94131088,  31.73221207,  17.55354691,  24.52309036,\n",
      "        11.09146595,  30.2763176 ,  15.25742817,   2.19598794,\n",
      "        -0.92703599,   3.26475167,   2.54810739,  13.71952534,\n",
      "        14.52134418,  14.38533497,   4.2838254 ,   3.48041177,\n",
      "        17.30356979,  13.25817585], dtype=float32)]\n",
      "iter:300, train_loss: 24.743704, test_loss: 247.515228\n",
      "test prediction parameters results: [array([ -1.93935471e+01,  -1.82407265e+01,  -1.88649864e+01,\n",
      "        -1.91259232e+01,  -1.89816971e+01,   7.83454478e-01,\n",
      "        -5.41655481e-01,  -2.20991537e-01,  -1.24651897e+00,\n",
      "         5.93383238e-03,  -4.98225629e-01,   1.37938607e+00,\n",
      "        -1.56568451e+01,  -1.61518478e+01,  -1.76980324e+01,\n",
      "        -1.91704082e+01,  -1.83783169e+01,  -1.78364716e+01,\n",
      "        -1.88541832e+01,  -1.98915787e+01,  -1.90997505e+01,\n",
      "        -2.60977507e+00,   4.70958464e-02,  -2.06310675e-01,\n",
      "         6.66795969e+00,   5.86841536e+00,  -2.08129234e+01,\n",
      "        -2.02704239e+01,  -2.11081810e+01,  -2.21297741e+01,\n",
      "        -2.16928272e+01,  -2.15525990e+01,  -2.14675789e+01,\n",
      "        -2.31580429e+01,  -2.23629074e+01,   1.68113194e+01,\n",
      "         1.44628878e+01,   1.19538469e+01,   1.26868296e+01,\n",
      "         1.51799440e+01,   1.33082361e+01,   1.36718950e+01,\n",
      "         2.17172546e+01,   9.28547764e+00,   1.44304399e+01,\n",
      "         1.22330980e+01,   1.12890711e+01,   1.25240107e+01,\n",
      "         1.72763062e+01,   9.34364414e+00], dtype=float32)]\n",
      "iter:400, train_loss: 0.742687, test_loss: 6.349802\n",
      "test prediction parameters results: [array([ 1.70644295,  1.0930804 ,  1.07649028,  0.44557276,  0.40208402,\n",
      "        1.27824867,  1.32717168,  1.15918458,  0.8677932 ,  1.28189027,\n",
      "        1.13654363,  0.28309932,  0.84515226,  1.13732445,  1.05417216,\n",
      "        1.36258113,  1.56504285,  1.67202032,  1.08326375,  1.64770973,\n",
      "        1.0887152 ,  0.38845697,  0.23998228,  0.94741905,  0.98755968,\n",
      "        1.33757937,  0.28707734,  0.21282473,  0.02682509,  1.00412261,\n",
      "       -0.02501497,  2.77926493,  6.14523363,  1.2398001 ,  1.83809221,\n",
      "        0.59776199,  3.18276143,  0.41610327,  2.49752522,  1.44049394,\n",
      "        5.03889704,  7.86020613,  0.72087038, -0.19327268,  3.08367109,\n",
      "        1.19006073,  2.39342427,  5.89883852,  1.19811642,  1.26000297], dtype=float32)]\n",
      "last test prediction parameters results: 492 0.561594 1.17258 [array([ 2.50898361,  3.3695662 ,  2.92975116,  3.52190113,  1.67425311,\n",
      "        1.0001899 ,  1.39521515,  0.46583807,  0.93886149,  0.66025746,\n",
      "        1.21944511,  1.15006864,  0.63560998,  1.14431965,  4.46614456,\n",
      "        1.30556715,  0.24360265,  0.78973687,  1.09636652,  1.02307022,\n",
      "        1.25497925,  0.89395893,  0.12779869,  0.83190882,  0.13971843,\n",
      "        0.78627765,  1.56708205,  1.50119007,  1.39061224,  1.15775216,\n",
      "        0.64699399,  3.19177532,  0.51240146,  0.83387554,  2.98102975,\n",
      "        1.10026038,  0.59335816,  0.7036382 ,  0.54637039, -0.03941809,\n",
      "        0.38444483,  1.18315506, -0.0112444 ,  0.80344379,  0.58730376,\n",
      "        0.46000564,  0.78147972,  0.06009926,  0.51942933,  0.96379793], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# tensorflow nn\n",
    "#unfolded version\n",
    "#reference code: https://github.com/yl3829/Spring2018-Project5-grp5/blob/master/lib/model_tb.py  \n",
    "\n",
    "# D = tf.placeholder(dytpe=np.floate32)\n",
    "# w1_1 = tf.Variable((18,79),name='W1_1')\n",
    "# w1_2 = tf.Variable((61,79),name='W1_2')\n",
    "# b1 = tf.Variable((79,),name='b1')\n",
    "# param = [w1_1,w1_2,b1]\n",
    "tf.reset_default_graph()\n",
    "x1=tf.placeholder(shape=(None, 18), dtype=tf.float32)\n",
    "x2=tf.placeholder(shape=(None, 61), dtype=tf.float32)\n",
    "y =tf.placeholder(shape=(None, ), dtype=tf.float32)\n",
    "\n",
    "#\n",
    "W1_1 = tf.get_variable('W1_1', shape=(18, 79))\n",
    "W1_2 = tf.get_variable('W1_2', shape=(61, 79))\n",
    "b1 = tf.get_variable('b1', shape=(1, 79))\n",
    "    \n",
    "o1_1 = tf.matmul(x1, W1_1)\n",
    "o1_2 = tf.matmul(x2, W1_2)\n",
    "o1 = o1_1 + o1_2 + b1\n",
    "o1 = tf.nn.sigmoid(o1)\n",
    "\n",
    "W2_1 = tf.get_variable('W2_1', shape=(61, 1))\n",
    "W2_2 = tf.get_variable('W2_2', shape=(79, 1))\n",
    "b2 = tf.get_variable('b2', shape=(1, 1))\n",
    "\n",
    "o2_1 = tf.matmul(x2, W2_1)\n",
    "o2_2 = tf.matmul(o1, W2_2)\n",
    "o2 = o2_1 + o2_2 + b2\n",
    "o2 = tf.reshape(o2, (-1, ))\n",
    "\n",
    "saver = tf.train.Saver([W1_1, W1_2, b1, W2_1, W2_2, b2])\n",
    "#\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y, o2)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.11)\n",
    "train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    \n",
    "# layer1_out  = tf.nn.sigmoid(tf.matmul(input1,w1_1) + tf.matmul(input2,w1_2) + b1) # tanh would be better\n",
    "# # example to minimize layer1 out put\n",
    "# losses = layer2_out - D\n",
    "# loss = tf.reduce_mean(losses)\n",
    "# trainer = tf.train.AdamOptimizer()\n",
    "# gradients = trainer.compute_gradients(self.loss)\n",
    "# optimizer = trainer.apply_gradients(gradients)\n",
    "\n",
    "#train-test_splie\n",
    "msk = np.random.rand(len(new_tv_info)) < 0.85\n",
    "tv_train = new_tv_info[msk]\n",
    "tv_test = new_tv_info[~msk]\n",
    "batch_size=50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(493):\n",
    "        x1_train = tv_train.iloc[step:step+batch_size, 66:84].values \n",
    "        x2_train = np.concatenate((tv_train.iloc[step:step+batch_size, 3:11].values, tv_train.iloc[step:step+batch_size, 14:67].values), 1) \n",
    "        y_train = tv_train.iloc[step:step+batch_size, 2].values \n",
    "            \n",
    "        x1_test = tv_test.iloc[step:step+batch_size, 66:84].values \n",
    "        x2_test = np.concatenate((tv_test.iloc[step:step+batch_size, 3:11].values, tv_test.iloc[step:step+batch_size, 14:67].values), 1) \n",
    "        y_test = tv_test.iloc[step:step+batch_size, 2].values \n",
    "            \n",
    "        _train_loss, _ = sess.run([loss, train_op],feed_dict={x1: x1_train,\n",
    "                                              x2: x2_train,\n",
    "                                              y: y_train})\n",
    "            \n",
    "        _test_loss= sess.run([loss],feed_dict={x1: x1_test,\n",
    "                                              x2: x2_test,\n",
    "                                              y: y_test})\n",
    "        # predict\n",
    "        D_predict = sess.run([o2], feed_dict={x1:x1_test,x2:x2_test})\n",
    "        para_pred = sess.run([W1_1, W1_2, b1, W2_1, W2_2, b2], feed_dict={x1:x1_test,x2:x2_test})\n",
    "        #results, _ = sess.run([output]) #print parameters, W1_1 etc..\n",
    "            \n",
    "        if step % 100==0:\n",
    "            saver.save(sess, 'C:/Users/wyd15/Desktop/tv_model/tv_modelslack.ckpt', global_step=step)\n",
    "            print(\"iter:%d, train_loss: %f, test_loss: %f\"%(step, _train_loss,  _test_loss[0]))\n",
    "            print('test prediction parameters results:', D_predict)\n",
    "            #print('predicted parameters:', para_pred)\n",
    "    print('last test prediction parameters results:', step, _train_loss,  _test_loss[0], D_predict)\n",
    "    paras=para_pred\n",
    "                #print('output:', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===== printing paramter: W1_1 ===== \n",
      "[[  1.65832207e-01  -3.80816460e-02   8.05306971e-01   1.77482605e+00\n",
      "    1.66702613e-01   7.75866210e-03   9.69515383e-01  -4.41772699e-01\n",
      "   -1.28720015e-01   8.32836866e-01   1.50457010e-01  -9.32666600e-01\n",
      "    2.00296116e+00  -1.74888289e+00  -5.21924019e-01  -9.50068086e-02\n",
      "   -1.90699071e-01   7.74878114e-02   9.15752500e-02  -2.30156630e-01\n",
      "    7.46385098e-01  -1.33213326e-01   2.05854750e+00  -1.52027547e-01\n",
      "   -2.35884219e-01   2.46063963e-01   6.28897011e-01   5.51505834e-02\n",
      "    1.19075581e-01   8.09076369e-01  -1.88010788e+00  -4.44552392e-01\n",
      "   -1.86735094e+00   7.07626820e-01  -2.39217982e-01  -9.87914085e-01\n",
      "   -1.64100274e-01  -2.69697607e-02  -1.93583965e-01  -4.55423929e-02\n",
      "   -9.71991122e-02   8.33238810e-02   1.83138597e+00  -2.32294157e-01\n",
      "   -1.81040376e-01  -8.32905024e-02   8.84145647e-02  -1.60633922e-01\n",
      "   -7.66483992e-02   2.33474448e-01   1.25416413e-01   8.60894859e-01\n",
      "    2.44112805e-01   2.21760288e-01  -1.14922225e-02  -2.08810878e+00\n",
      "    3.23756486e-02  -2.42462933e-01   1.79701328e+00  -1.61170125e+00\n",
      "   -1.98492363e-01  -4.33581471e-02  -3.64799201e-02  -3.31570767e-02\n",
      "   -1.99321985e-01  -8.09774935e-01   6.63374811e-02  -8.08261335e-02\n",
      "    2.05087408e-01  -1.75246850e-01  -1.04919240e-01   7.50753224e-01\n",
      "    1.89583942e-01  -1.83912051e+00  -3.20534259e-02   1.63982773e+00\n",
      "    3.12112272e-03  -4.25938219e-02   2.18203664e+00]\n",
      " [  5.98372668e-02   1.57400951e-01   7.95089304e-01   1.83049166e+00\n",
      "   -2.16778129e-01  -6.40805364e-02  -1.29862085e-01   1.11900821e-01\n",
      "   -1.19924009e-01   6.57205462e-01  -1.76265329e-01  -5.09391308e-01\n",
      "    3.51060957e-01   5.92343695e-02  -6.77658737e-01  -7.22189993e-02\n",
      "   -9.33442414e-02   1.62454739e-01  -6.68073595e-02  -6.61593527e-02\n",
      "    4.13852870e-01   1.18775740e-01   2.16295481e+00  -1.49354398e-01\n",
      "    1.86736152e-01  -1.46516114e-01  -6.48510233e-02  -1.07508600e-01\n",
      "    3.12289745e-02   4.53507900e-01  -1.86035001e+00  -6.08934462e-01\n",
      "   -1.96573925e+00   8.22081506e-01   1.26442164e-02  -8.40122104e-01\n",
      "    1.21377602e-01  -1.53384194e-01   7.34471530e-02   1.84213206e-01\n",
      "   -1.31698415e-01  -1.07175529e-01   1.89922059e+00   1.78414240e-01\n",
      "   -2.21570194e-01  -2.46045291e-02   3.00017148e-02  -1.75531060e-01\n",
      "   -7.34468549e-02  -1.71173826e-01  -1.76490396e-02   4.14533198e-01\n",
      "   -2.20093995e-01  -2.10430205e-01  -1.17861494e-01  -8.87875915e-01\n",
      "   -1.75529271e-01   8.79710764e-02   1.03729449e-01   1.34301871e-01\n",
      "    2.44671330e-01   9.44681615e-02   1.35068849e-01   2.44644150e-01\n",
      "    2.41809338e-02  -6.90649271e-01  -6.47983253e-02  -2.18852803e-01\n",
      "    1.47742823e-01   1.87219366e-01  -2.03029513e-01   1.04833432e-01\n",
      "    2.06530616e-01  -1.69237673e+00   1.01653472e-01   1.66740823e+00\n",
      "    1.34641781e-01   1.40142843e-01   1.94752300e+00]\n",
      " [  1.99743822e-01   1.65557429e-01   7.70209312e-01   2.07976961e+00\n",
      "   -6.24919236e-02   5.07555753e-02   8.28417122e-01   1.15555763e-01\n",
      "    2.28146121e-01   5.61599910e-01   2.18057528e-01  -8.94000530e-01\n",
      "    1.76313710e+00  -2.08552241e+00  -4.46497142e-01   1.72880098e-01\n",
      "    1.36604980e-01   4.82021272e-03   2.23400071e-01   1.79781929e-01\n",
      "    7.36436069e-01   6.64068609e-02   2.21317363e+00  -9.82072204e-02\n",
      "   -1.17856219e-01  -2.88255662e-02   8.04717720e-01  -1.63023144e-01\n",
      "    1.90086409e-01   7.54577577e-01  -1.82053494e+00  -8.81178439e-01\n",
      "   -2.00304127e+00   8.14051092e-01   2.14570001e-01  -6.44614041e-01\n",
      "   -1.37088448e-02   1.96717680e-03  -1.69274658e-02  -9.01228562e-02\n",
      "   -2.07120031e-02  -1.39455065e-01   1.78244293e+00  -2.14553088e-01\n",
      "   -1.48414016e-01  -1.68216407e-01   1.07075617e-01   3.88474613e-02\n",
      "   -3.35123688e-02  -2.22043499e-01  -6.26337081e-02   9.45962012e-01\n",
      "    1.81361586e-02  -1.27804041e-01   8.60949904e-02  -1.70555556e+00\n",
      "   -7.80617893e-02   7.93669671e-02   2.07720423e+00  -1.75746119e+00\n",
      "    1.07437864e-01  -1.55895293e-01  -1.31037831e-02  -2.23523974e-01\n",
      "   -1.66142568e-01  -7.90767670e-01   1.42851338e-01  -1.76596910e-01\n",
      "    8.38858932e-02   9.28501785e-03  -1.19250700e-01   6.08482778e-01\n",
      "    1.99098423e-01  -2.13194799e+00   2.08379254e-01   1.59091496e+00\n",
      "   -9.89494324e-02  -1.88312978e-02   1.78269386e+00]\n",
      " [ -5.16465753e-02  -6.51713610e-02   5.42724550e-01   1.87789631e+00\n",
      "    2.19598874e-01   1.05036244e-01   1.98373515e-02   5.86669110e-02\n",
      "    3.90737504e-02   7.06057549e-01   1.46035627e-01  -2.51239181e-01\n",
      "    5.90624250e-02  -2.18414769e-01  -6.19902432e-01   1.46155939e-01\n",
      "   -2.13271573e-01   2.29835376e-01  -9.40238982e-02   6.93941563e-02\n",
      "    3.93258482e-01  -5.19827902e-02   2.07452321e+00  -1.19958460e-01\n",
      "    1.85917929e-01  -3.02343369e-02   1.14110045e-01   6.77776188e-02\n",
      "   -1.98173821e-01   8.01005125e-01  -2.06552434e+00  -7.02282012e-01\n",
      "   -1.99095011e+00   7.10021019e-01  -6.73506260e-02  -8.53107035e-01\n",
      "   -1.23218343e-01   6.25783056e-02   1.26821205e-01   5.53692728e-02\n",
      "   -1.63885862e-01   1.92172602e-01   1.78216445e+00   9.96810347e-02\n",
      "    1.23711035e-01   1.00031063e-01   1.03992209e-01   2.00636819e-01\n",
      "    6.03325814e-02   1.21654943e-01   1.24123052e-01   6.20940506e-01\n",
      "    1.81306854e-01   1.55008510e-01   1.26647636e-01  -9.52168107e-01\n",
      "    1.11514971e-01   2.35824928e-01   1.88153028e-01   1.07956067e-01\n",
      "   -8.26299340e-02   2.30863497e-01  -8.69663656e-02   5.52691668e-02\n",
      "    1.32306680e-01  -8.07411432e-01  -2.17233956e-01   2.44153887e-02\n",
      "    1.02670476e-01  -1.29392847e-01   1.45017654e-02  -2.43476152e-01\n",
      "    3.99304479e-02  -1.88197744e+00   1.05963930e-01   1.35323930e+00\n",
      "   -2.12522238e-01   1.01961806e-01   1.82667053e+00]\n",
      " [ -2.42025807e-01  -1.63938344e-01   7.93513000e-01   2.08969569e+00\n",
      "   -2.48257518e-01   2.23669812e-01   5.93917608e-01  -3.30811292e-01\n",
      "    2.08908185e-01   6.98822916e-01  -1.82998747e-01  -9.98336017e-01\n",
      "    2.00822186e+00  -1.95373952e+00  -7.10775137e-01   7.58536905e-02\n",
      "    2.40917310e-01   2.42706403e-01   1.54520437e-01   2.72313207e-02\n",
      "    4.94607896e-01  -1.38878822e-03   2.03347850e+00  -1.14083171e-01\n",
      "    1.10485777e-01  -1.80121750e-01   6.81238890e-01  -2.41478026e-01\n",
      "   -2.28096962e-01   5.23255289e-01  -2.24713111e+00  -8.27742934e-01\n",
      "   -1.93649137e+00   5.51582932e-01  -1.47385031e-01  -6.27506435e-01\n",
      "    1.11577824e-01  -7.42694139e-02  -1.89377964e-02   1.60311237e-01\n",
      "   -1.38045937e-01  -1.66257620e-02   1.92199731e+00   1.47366479e-01\n",
      "   -1.85515136e-01   7.83349127e-02  -1.07544243e-01   2.11844370e-01\n",
      "    4.51007038e-02   2.30611190e-01  -1.70078442e-01   8.67760420e-01\n",
      "    2.18473658e-01  -1.22195899e-01   1.76897720e-01  -1.87077975e+00\n",
      "    3.55958194e-02   6.67091459e-02   2.00552678e+00  -1.47479534e+00\n",
      "   -8.41296166e-02  -1.87096328e-01  -1.19729042e-01  -1.78201741e-03\n",
      "    4.72164601e-02  -7.09782362e-01   2.44002566e-01  -1.32184118e-01\n",
      "    4.32962328e-02   6.95938319e-02   1.95078596e-01   1.00810456e+00\n",
      "    9.98334587e-03  -1.82308435e+00   2.03397319e-01   1.31568217e+00\n",
      "   -9.37646031e-02  -1.69433653e-01   1.99136305e+00]\n",
      " [  1.98734000e-01  -2.07520336e-01   7.62040436e-01   1.77729142e+00\n",
      "    8.77459794e-02  -6.84843212e-02  -1.81732699e-01  -2.15905141e-02\n",
      "   -4.52730060e-03   7.93285489e-01   1.24936178e-01  -2.42609113e-01\n",
      "    2.86321431e-01  -3.56892757e-02  -6.25729680e-01  -1.97855532e-02\n",
      "    9.79993194e-02  -1.49022400e-01  -2.36173585e-01   1.77389070e-01\n",
      "    6.03155673e-01  -1.17942259e-01   1.91175842e+00   9.20329541e-02\n",
      "    1.08462796e-01  -1.55821934e-01  -1.79308832e-01  -1.15753621e-01\n",
      "    2.32584432e-01   8.75645399e-01  -1.82752454e+00  -4.18309987e-01\n",
      "   -1.91138458e+00   5.79760730e-01  -5.86882234e-02  -8.65264773e-01\n",
      "    4.03691381e-02  -1.93257064e-01  -9.31638628e-02   8.42805058e-02\n",
      "    1.31028488e-01   1.36670306e-01   2.05683708e+00   2.27890149e-01\n",
      "    8.03390294e-02  -8.35916102e-02  -1.44411191e-01   6.61476105e-02\n",
      "    5.55987507e-02   1.77604601e-01  -1.29857808e-02   6.51247442e-01\n",
      "   -1.78329796e-02   2.41126582e-01   1.02339372e-01  -7.48425901e-01\n",
      "   -2.14384034e-01  -6.27750605e-02  -1.67072549e-01   1.71575665e-01\n",
      "    2.18938664e-01   1.35195479e-01  -9.42361206e-02   2.90962011e-02\n",
      "   -3.15423608e-02  -6.92124128e-01  -1.76347882e-01  -1.95192695e-01\n",
      "    1.94827840e-01   1.58351704e-01   7.46430308e-02   3.29430215e-02\n",
      "   -2.30989993e-01  -2.14666200e+00  -3.40204239e-02   1.48633027e+00\n",
      "   -4.43291962e-02  -1.10546365e-01   1.82728708e+00]\n",
      " [  2.47395486e-02  -1.41146913e-01   5.36127985e-01   1.81656682e+00\n",
      "   -7.91093260e-02  -1.60540044e-01   9.35127378e-01  -5.19612730e-01\n",
      "   -8.00452083e-02   7.52150953e-01  -2.21229702e-01  -9.57548022e-01\n",
      "    2.00803232e+00  -2.05549669e+00  -5.25620341e-01  -2.23008543e-01\n",
      "    1.25018016e-01   2.44919285e-01   1.40927032e-01  -2.31062457e-01\n",
      "    4.43330467e-01  -1.53161883e-02   1.84159052e+00   1.22343078e-01\n",
      "   -1.32488549e-01   1.35600373e-01   1.02974927e+00  -1.28754988e-01\n",
      "   -1.22335777e-01   8.31803620e-01  -1.80074120e+00  -5.71040273e-01\n",
      "   -2.11013460e+00   7.77027607e-01  -6.96264356e-02  -7.31634200e-01\n",
      "    2.18710378e-01   9.77297127e-03   1.71468899e-01  -2.00667515e-01\n",
      "   -7.90982991e-02  -2.55399942e-02   1.74409020e+00  -1.48056149e-01\n",
      "    4.01187092e-02  -9.39923525e-02   2.23829105e-01  -1.68237567e-01\n",
      "    1.14696130e-01  -8.98406506e-02  -2.13513330e-01   8.64475131e-01\n",
      "    3.47610861e-02  -1.92757547e-01   1.81139752e-01  -1.69236088e+00\n",
      "    2.36458912e-01  -6.81556314e-02   1.90141964e+00  -1.75638616e+00\n",
      "   -2.17769340e-01  -1.94591299e-01   1.12991825e-01  -2.29503170e-01\n",
      "   -2.16394603e-01  -1.10512722e+00   4.73174602e-02  -1.10007003e-01\n",
      "    4.77579683e-02   1.93480924e-01   7.63742775e-02   7.79358149e-01\n",
      "   -9.81553346e-02  -1.89219677e+00   2.18546256e-01   1.48123026e+00\n",
      "   -2.01522604e-01   1.21654227e-01   2.09296918e+00]\n",
      " [  4.88108844e-02  -2.23479122e-01   5.20159900e-01   2.16985989e+00\n",
      "    1.94841698e-01   1.67887494e-01   2.42513418e-01  -2.27177650e-01\n",
      "    1.19283959e-01   7.66496181e-01  -5.59586883e-02  -2.10270897e-01\n",
      "    7.03153759e-02   1.97556898e-01  -4.58231151e-01   1.81092322e-03\n",
      "    1.41440019e-01  -2.36133933e-02  -2.57982314e-02  -1.94191173e-01\n",
      "    7.48350322e-01   1.69733211e-01   2.19343710e+00   9.70095396e-04\n",
      "    7.62566775e-02   2.20901921e-01  -2.27576405e-01   1.19634286e-01\n",
      "   -7.28006959e-02   4.19281483e-01  -2.26857638e+00  -9.04892743e-01\n",
      "   -2.09752536e+00   6.45044208e-01   6.00980669e-02  -6.32604182e-01\n",
      "   -4.12534773e-02  -1.85605496e-01  -1.28928438e-01   2.03207985e-01\n",
      "    9.64839309e-02  -2.35942498e-01   1.89761889e+00   1.80690214e-01\n",
      "    8.82538706e-02   2.18166575e-01  -2.02491030e-01  -1.21439993e-02\n",
      "    7.45564252e-02  -7.15183467e-02  -1.51225805e-01   8.37416112e-01\n",
      "   -1.07817650e-01  -2.57279724e-02  -1.30387902e-01  -8.41491044e-01\n",
      "   -4.46397364e-02  -6.87389970e-02  -1.02247164e-01   8.44089836e-02\n",
      "    1.39078423e-01   7.97907561e-02   2.23377839e-01  -1.75504789e-01\n",
      "    1.42532095e-01  -6.74598217e-01   1.63279966e-01   1.27359852e-01\n",
      "    8.96989256e-02  -5.35596013e-02   1.87593654e-01  -8.45186636e-02\n",
      "    1.99531481e-01  -2.08174205e+00   2.18474373e-01   1.41900420e+00\n",
      "    3.44755799e-02  -5.59442788e-02   1.94011748e+00]\n",
      " [  2.24580988e-01   7.47760385e-02   5.48781931e-01   2.03244472e+00\n",
      "   -1.25134587e-01   1.36192456e-01   5.57309628e-01  -4.02059734e-01\n",
      "   -8.38777125e-02   7.22632945e-01   4.74984944e-03  -1.18159759e+00\n",
      "    2.07033110e+00  -1.91379023e+00  -5.48415780e-01   8.14877003e-02\n",
      "   -2.23216504e-01  -1.57302618e-02  -3.59497517e-02   1.98701277e-01\n",
      "    8.20307076e-01  -1.33419916e-01   2.01402235e+00  -1.34683043e-01\n",
      "   -1.36675656e-01  -1.78798005e-01   7.61998713e-01  -9.94783640e-03\n",
      "   -1.15912229e-01   4.59937751e-01  -1.90016937e+00  -4.50633317e-01\n",
      "   -2.20042872e+00   8.50255370e-01  -1.33885324e-01  -9.78543937e-01\n",
      "   -9.97935236e-02   4.32982594e-02   8.85916799e-02   2.21955404e-01\n",
      "   -8.86744559e-02  -2.23163962e-01   1.96143007e+00   6.56888336e-02\n",
      "   -1.09513536e-01  -1.32362902e-01   9.94142145e-02   2.38077417e-01\n",
      "    2.39468709e-01  -1.41422465e-01   8.57525617e-02   9.91379261e-01\n",
      "    2.16499373e-01   8.99843872e-03   7.80384243e-03  -1.83933902e+00\n",
      "    2.18803898e-01   3.55481952e-02   1.78079200e+00  -1.39571798e+00\n",
      "    8.10081810e-02  -2.22835928e-01   1.91507772e-01   1.12401284e-01\n",
      "   -5.73019832e-02  -1.02857423e+00   2.30411246e-01  -2.11062953e-01\n",
      "   -1.53314516e-01   6.43906742e-02  -1.75720870e-01   7.28752315e-01\n",
      "    9.00101811e-02  -1.82150137e+00   4.44370061e-02   1.72306406e+00\n",
      "    1.98393270e-01   2.30422452e-01   1.74171388e+00]\n",
      " [  3.35315317e-02  -2.00261295e-01   4.41361010e-01   1.93122768e+00\n",
      "   -1.13254860e-01   5.87746650e-02   8.52433071e-02  -1.41910195e-01\n",
      "    3.88981551e-02   8.26233149e-01  -1.19525120e-01  -3.18069786e-01\n",
      "    6.83243796e-02   1.98837712e-01  -5.94215691e-01  -1.10441893e-01\n",
      "    2.29535863e-01   2.20813498e-01  -5.02138436e-02   5.31293899e-02\n",
      "    8.50365520e-01   1.89985201e-01   1.82868600e+00  -1.37991160e-01\n",
      "    5.20351976e-02   2.31817812e-02   5.62204048e-02   1.55323669e-01\n",
      "    4.28895205e-02   8.67005944e-01  -2.04996872e+00  -7.07427680e-01\n",
      "   -1.81214166e+00   6.87319160e-01   1.45348683e-01  -1.05767369e+00\n",
      "   -1.66074723e-01   1.52120098e-01   2.15937719e-01  -2.33345315e-01\n",
      "    8.29421431e-02  -1.53337359e-01   2.06907773e+00   3.97217423e-02\n",
      "    1.65175036e-01  -1.67300880e-01  -1.67859972e-01   3.04127485e-02\n",
      "   -2.14754045e-03   1.15886182e-02   2.52981931e-02   8.43857706e-01\n",
      "    1.59735218e-01  -1.32371187e-01  -1.62262559e-01  -9.99698162e-01\n",
      "   -5.51233739e-02  -8.54948610e-02   1.33370116e-01  -2.02457905e-01\n",
      "    4.26940173e-02  -5.17508239e-02  -2.26460084e-01   1.89688310e-01\n",
      "    3.34795862e-02  -1.02600133e+00   2.30506912e-01   9.01462585e-02\n",
      "    9.71504897e-02  -6.68110847e-02  -1.17655694e-02  -1.05216436e-01\n",
      "    1.81137308e-01  -2.15753436e+00  -2.21965939e-01   1.73645425e+00\n",
      "   -1.39575899e-02   4.80156690e-02   1.98715150e+00]\n",
      " [  4.94881123e-02  -1.70308620e-01   4.48226243e-01   1.85296059e+00\n",
      "    5.38150519e-02  -7.28237033e-02   9.13368881e-01  -2.18515456e-01\n",
      "    1.11659959e-01   5.19406855e-01  -1.93690702e-01  -1.04022920e+00\n",
      "    1.97578025e+00  -1.91511488e+00  -8.96950722e-01   1.01627395e-01\n",
      "    8.66725594e-02   1.28383800e-01   1.42601982e-01   1.52730092e-01\n",
      "    6.24239743e-01   2.11054534e-02   2.31283998e+00  -3.98337990e-02\n",
      "   -2.32195795e-01  -1.37054086e-01   9.44632053e-01  -9.54696685e-02\n",
      "    2.16888413e-01   4.96093899e-01  -2.06647992e+00  -4.19933289e-01\n",
      "   -1.83731091e+00   4.29973781e-01  -9.34620649e-02  -7.40004361e-01\n",
      "    5.35262078e-02  -1.68005079e-01  -2.30394363e-01  -1.69242755e-01\n",
      "   -2.16639563e-01  -1.18853286e-01   1.86738110e+00   2.27943853e-01\n",
      "   -2.01162249e-01  -1.49651289e-01   1.43420175e-01   2.05510423e-01\n",
      "   -9.60174501e-02   2.26354197e-01  -6.08235002e-02   7.11219788e-01\n",
      "    2.31979772e-01  -9.66338813e-03  -6.50525093e-03  -1.76969278e+00\n",
      "    8.97295922e-02  -1.34702444e-01   2.19033170e+00  -1.37022543e+00\n",
      "    7.70850480e-03  -2.42650732e-01   2.38057449e-01  -1.41180074e-02\n",
      "    2.46882901e-01  -7.69601882e-01  -2.36595303e-01  -4.27200645e-02\n",
      "   -5.35189211e-02   7.98579305e-02  -1.82068333e-01   6.46944463e-01\n",
      "    1.44503519e-01  -1.87257004e+00   5.79869300e-02   1.50982702e+00\n",
      "    1.22032061e-01  -1.74731016e-02   2.10048509e+00]\n",
      " [ -7.85470158e-02   7.94442445e-02   7.88903058e-01   2.17649484e+00\n",
      "    6.27371818e-02   1.25136182e-01  -7.06552491e-02  -1.60672575e-01\n",
      "    1.14628419e-01   7.47509837e-01  -1.91203266e-01  -4.69024450e-01\n",
      "    3.08548927e-01  -9.93783474e-02  -6.72062993e-01  -2.45581046e-01\n",
      "    1.72728881e-01  -1.16383165e-01   3.03941220e-02   3.99150401e-02\n",
      "    7.02263355e-01   2.26273671e-01   2.08604121e+00  -2.32578069e-01\n",
      "   -1.12208635e-01   1.04177251e-01   2.33449921e-01  -1.93554208e-01\n",
      "   -1.13604173e-01   4.64447796e-01  -1.97159469e+00  -6.33025825e-01\n",
      "   -2.09763741e+00   6.72159612e-01   2.34560475e-01  -8.61063361e-01\n",
      "   -3.78073454e-02  -2.41285548e-01  -2.43609309e-01  -2.38677025e-01\n",
      "    1.60184279e-01  -2.14125961e-02   1.99291432e+00  -1.94289356e-01\n",
      "   -3.93716395e-02   1.94652602e-01  -2.03833684e-01  -1.21182993e-01\n",
      "   -2.44297221e-01   5.80606312e-02   2.02887431e-01   7.13253736e-01\n",
      "    2.44507045e-02   1.06684491e-01   1.66290149e-01  -1.14336717e+00\n",
      "   -1.50917619e-02   1.11792371e-01   2.28482902e-01   2.07319587e-01\n",
      "    1.84449106e-02   2.16957554e-01   2.02723727e-01   2.43761092e-02\n",
      "   -1.16723359e-01  -8.89851868e-01  -1.98587775e-04  -2.35370100e-02\n",
      "   -1.38528556e-01   2.12978944e-01   1.30783483e-01  -2.28466943e-01\n",
      "    1.88694671e-01  -2.03438711e+00  -7.36333430e-03   1.31394935e+00\n",
      "    1.81317881e-01  -4.93582636e-02   2.19464159e+00]\n",
      " [ -1.25595957e-01  -3.28064412e-02   7.24058926e-01   2.17513490e+00\n",
      "   -7.61313885e-02  -1.29164368e-01   7.50604510e-01  -1.85211465e-01\n",
      "   -2.70011276e-02   5.46583176e-01  -1.66882887e-01  -1.04000962e+00\n",
      "    1.90265810e+00  -1.85633206e+00  -7.63159573e-01   1.67130157e-01\n",
      "    1.85635015e-01  -1.26204938e-01  -2.29597524e-01  -2.45071396e-01\n",
      "    8.24090779e-01   2.11128756e-01   2.10259843e+00  -1.03807077e-01\n",
      "   -1.25709459e-01  -1.92318469e-01   8.82529438e-01  -2.14885682e-01\n",
      "   -5.82580864e-02   7.60739326e-01  -2.17064691e+00  -7.57084787e-01\n",
      "   -2.16580868e+00   7.04222322e-01  -7.78078735e-02  -9.85396922e-01\n",
      "    1.45089671e-01  -1.36469364e-01  -1.88631520e-01  -3.70616764e-02\n",
      "   -2.42623746e-01   7.76789039e-02   2.03810263e+00   1.68254122e-01\n",
      "    1.68113574e-01  -2.30614230e-01   8.56870264e-02   1.81767926e-01\n",
      "    2.49064714e-02   2.00843468e-01   6.52375370e-02   1.00090361e+00\n",
      "   -3.75402123e-02  -1.07422918e-02  -8.65943879e-02  -2.07197809e+00\n",
      "    1.97455451e-01  -1.28746510e-01   1.95052040e+00  -1.77003074e+00\n",
      "   -2.13284254e-01  -2.32584476e-01   4.10269648e-02  -2.17429966e-01\n",
      "   -1.37036294e-02  -9.71996486e-01  -7.43056983e-02  -2.25893974e-01\n",
      "   -2.08875626e-01   1.55154184e-01  -2.47632593e-01   8.62650931e-01\n",
      "   -1.65523574e-01  -2.14023972e+00  -1.82194710e-02   1.54189014e+00\n",
      "    2.41634205e-01   1.64473370e-01   2.12765169e+00]\n",
      " [ -9.33371335e-02  -1.49825364e-02   8.17287385e-01   1.87633002e+00\n",
      "   -2.35703185e-01  -1.36977404e-01  -9.10024568e-02  -1.50579184e-01\n",
      "    1.11823231e-02   7.79267311e-01   1.19052634e-01  -3.39347392e-01\n",
      "    5.18095084e-02  -1.29594151e-02  -6.99954331e-01   4.65482026e-02\n",
      "    2.89423317e-02  -1.89774990e-01  -4.58712876e-03   8.06770176e-02\n",
      "    5.10839343e-01  -6.17701113e-02   2.05910754e+00  -7.50026107e-02\n",
      "    2.07782850e-01   7.58775920e-02  -8.90516862e-02  -2.26146758e-01\n",
      "    1.19420096e-01   6.38470113e-01  -2.24133062e+00  -9.08089817e-01\n",
      "   -2.05861306e+00   8.21075737e-01   2.40227029e-01  -6.98431015e-01\n",
      "   -7.56345689e-03   2.11184636e-01   2.19037995e-01   1.61449537e-01\n",
      "    2.32203916e-01   1.80073842e-01   2.14501119e+00   2.32999489e-01\n",
      "   -2.05905870e-01   8.25482160e-02   3.74303311e-02  -8.73602629e-02\n",
      "   -1.68634683e-01  -1.31904781e-02  -5.69906831e-02   5.86412013e-01\n",
      "   -1.09526649e-01   1.95028618e-01  -1.37601346e-02  -8.09059680e-01\n",
      "   -9.91362780e-02  -2.21658006e-01   1.74845964e-01  -2.52845734e-01\n",
      "   -9.44007337e-02   1.11949220e-01  -4.12330776e-02   2.43462190e-01\n",
      "    2.45893076e-01  -7.89607227e-01   1.95943430e-01  -2.43152022e-01\n",
      "    1.82082206e-02   3.23175341e-02   5.38748354e-02  -1.00461327e-01\n",
      "   -1.75673306e-01  -1.93618572e+00  -1.12472028e-02   1.71626520e+00\n",
      "   -2.21929997e-01  -1.52485847e-01   2.11319017e+00]\n",
      " [ -4.74598110e-02  -2.35627592e-03   8.34138215e-01   1.75614333e+00\n",
      "   -8.19655210e-02   1.78536102e-01   7.63970494e-01  -2.66726345e-01\n",
      "    1.22933194e-01   8.69264960e-01  -2.46188894e-01  -8.12436283e-01\n",
      "    1.74513936e+00  -2.07593298e+00  -8.47225010e-01  -5.67233711e-02\n",
      "    3.11402529e-02   1.32371917e-01  -5.71863651e-02  -1.16461918e-01\n",
      "    7.60099292e-01   4.52374369e-02   2.32573414e+00  -7.31184036e-02\n",
      "   -1.04294434e-01   1.03957504e-02   5.10527849e-01  -4.88496125e-02\n",
      "   -2.32197270e-01   5.92722714e-01  -1.84856963e+00  -7.63263464e-01\n",
      "   -2.05993032e+00   4.98147309e-01   2.23859742e-01  -1.01062763e+00\n",
      "   -4.70458716e-02  -1.04197010e-01  -5.03811240e-02  -5.77300712e-02\n",
      "    7.97072202e-02  -2.35355228e-01   2.17209530e+00   1.17696896e-01\n",
      "   -9.62229818e-02   1.87315896e-01  -2.19109446e-01   1.16000935e-01\n",
      "    5.98354489e-02  -1.46217257e-01   2.01256469e-01   1.07253671e+00\n",
      "   -1.69604421e-01   2.60750949e-03   5.27078062e-02  -1.87779009e+00\n",
      "    1.80258825e-01  -2.80939043e-02   2.04377937e+00  -1.66897297e+00\n",
      "   -1.39493316e-01  -9.00940746e-02  -2.12047935e-01   1.30651847e-01\n",
      "   -2.31646940e-01  -8.32295597e-01   7.14588612e-02  -1.47618487e-01\n",
      "   -1.03108853e-01   6.70653433e-02  -2.16359735e-01   5.43956041e-01\n",
      "    7.44612515e-03  -1.79568124e+00   7.59415179e-02   1.43983710e+00\n",
      "    4.68558818e-02  -1.82872862e-01   1.79963827e+00]\n",
      " [  1.94622979e-01  -2.37642899e-01   8.56741846e-01   1.91063797e+00\n",
      "    1.83790475e-02  -7.40219057e-02   1.90324277e-01  -4.68650348e-02\n",
      "   -8.25954825e-02   5.01434565e-01  -1.97605699e-01  -2.17185602e-01\n",
      "    1.58781875e-02   6.83183968e-03  -6.49972260e-01  -1.26143873e-01\n",
      "   -2.43484676e-01   1.10342935e-01   1.14380434e-01   2.33091861e-02\n",
      "    4.69153404e-01   9.14870203e-03   2.12318659e+00  -2.32636243e-01\n",
      "   -1.00004077e-01  -2.31987834e-01   3.70389386e-03  -1.83246315e-01\n",
      "    2.12926820e-01   8.40033054e-01  -2.25515056e+00  -6.57755554e-01\n",
      "   -1.89280283e+00   4.46189880e-01   1.87600479e-01  -6.97686911e-01\n",
      "   -2.78450996e-02   1.55556455e-01  -1.87395483e-01  -7.03498255e-04\n",
      "    3.21845859e-02   2.27517113e-01   2.17682338e+00   2.02514276e-01\n",
      "    1.21617392e-01  -1.16354048e-01   3.86312753e-02   2.10375890e-01\n",
      "    1.59791902e-01  -2.47291878e-01  -4.88090515e-02   5.74291289e-01\n",
      "    1.56643018e-01   1.79387942e-01   2.10428759e-01  -9.09958124e-01\n",
      "    5.70677072e-02   6.81984574e-02   2.22743332e-01  -9.32071209e-02\n",
      "   -1.87218428e-01   2.38599330e-02   7.20964819e-02  -2.57723182e-02\n",
      "    1.38653681e-01  -8.16857576e-01  -1.06801912e-01  -2.18281120e-01\n",
      "    2.05058947e-01   9.24275666e-02  -8.04151595e-03   1.90629154e-01\n",
      "   -8.45310539e-02  -2.14299870e+00  -2.20113933e-01   1.50934815e+00\n",
      "    8.98083299e-02   7.46912509e-02   2.16667438e+00]\n",
      " [  1.48039207e-01  -2.47560009e-01   5.78125417e-01   2.08300614e+00\n",
      "   -1.01672694e-01   6.85147494e-02   8.86714339e-01  -2.01018274e-01\n",
      "    1.82084098e-01   5.62950194e-01   2.28548631e-01  -9.09286022e-01\n",
      "    2.23585558e+00  -1.89008880e+00  -6.34286582e-01  -2.79946923e-02\n",
      "    1.86028525e-01  -1.34239390e-01  -1.22295335e-01  -4.82009053e-02\n",
      "    7.65700519e-01  -8.12218785e-02   2.19931626e+00   1.05684474e-01\n",
      "   -1.44777358e-01  -1.39325321e-01   6.21287525e-01   6.25997335e-02\n",
      "    1.19671062e-01   4.79961991e-01  -2.17383242e+00  -4.50469375e-01\n",
      "   -1.92072439e+00   5.13846457e-01   2.65732259e-02  -7.45604634e-01\n",
      "    2.16273963e-03   2.99748629e-02  -2.21228048e-01  -8.57152194e-02\n",
      "   -9.36636776e-02  -1.02602288e-01   2.09868050e+00  -2.34774306e-01\n",
      "    2.05746070e-01  -1.91474497e-01  -1.00217134e-01   1.99014649e-01\n",
      "   -5.50734997e-02  -2.16720611e-01  -5.23145497e-02   7.09800541e-01\n",
      "    8.20207745e-02  -1.76575780e-02   1.20686457e-01  -2.09934020e+00\n",
      "    1.32370248e-01   1.49859771e-01   2.11364198e+00  -1.42545676e+00\n",
      "   -1.28256366e-01   1.90185860e-01   9.19551700e-02   1.91688135e-01\n",
      "   -7.24083185e-03  -9.48736787e-01  -1.31615460e-01  -1.26987010e-01\n",
      "   -2.36941233e-01  -5.88907152e-02  -1.93257719e-01   8.85663152e-01\n",
      "    1.28409818e-01  -1.86803734e+00  -9.97711122e-02   1.53746247e+00\n",
      "   -2.82140374e-02   2.40057155e-01   1.70841599e+00]\n",
      " [ -2.41547808e-01   7.96557516e-02   8.27170074e-01   2.08742619e+00\n",
      "   -6.53181821e-02   1.76709697e-01   1.79825693e-01  -1.28409177e-01\n",
      "    6.02146834e-02   6.25599265e-01  -1.67369246e-01  -3.41628581e-01\n",
      "    3.42362732e-01  -1.62365511e-01  -4.53504741e-01   3.47519070e-02\n",
      "    2.32924417e-01  -2.06670374e-01  -1.95176557e-01  -7.30662942e-02\n",
      "    4.04561579e-01   8.70470554e-02   1.84728861e+00   1.68247774e-01\n",
      "    1.06279507e-01   1.07523665e-01  -1.05542786e-01  -3.08556408e-02\n",
      "    2.48300686e-01   4.12614107e-01  -1.87030566e+00  -6.24496520e-01\n",
      "   -2.28524184e+00   6.57202780e-01   1.15944132e-01  -5.96607208e-01\n",
      "   -1.64974183e-01   1.65468320e-01   5.64086884e-02  -7.23413825e-02\n",
      "    7.81549960e-02  -2.41039276e-01   1.71054924e+00   3.00304741e-02\n",
      "   -1.95375800e-01   1.33419141e-01   1.52862385e-01   4.09836322e-02\n",
      "   -5.94470948e-02   1.43764630e-01   6.32874519e-02   6.43073261e-01\n",
      "   -1.78028643e-02  -7.00569302e-02  -5.28255701e-02  -1.08873582e+00\n",
      "    8.34128410e-02   2.10774228e-01  -1.97789147e-01   3.09987236e-02\n",
      "   -1.35915533e-01  -5.10884076e-02  -1.34903401e-01   2.07945898e-01\n",
      "    1.85363933e-01  -1.11016691e+00   1.91562667e-01  -2.27307081e-02\n",
      "   -4.26879227e-02   1.25987843e-01   2.33195946e-01  -1.66292656e-02\n",
      "   -1.43369347e-01  -1.90149057e+00  -1.31410241e-01   1.41556001e+00\n",
      "    2.28107110e-01  -2.08259165e-01   1.99290478e+00]]\n",
      " ===== printing paramter: W1_2 ===== \n",
      "[[ 0.02530299  0.10664599  0.75140953 ..., -0.03674847 -0.18071637\n",
      "   1.88281071]\n",
      " [-0.06630699  0.02294751  0.55038959 ..., -0.0719011  -0.02760842\n",
      "   1.77603829]\n",
      " [ 0.13194145  0.08225454  0.51377738 ...,  0.03874175 -0.17059845\n",
      "   1.93120897]\n",
      " ..., \n",
      " [ 0.02974263 -0.09989332  0.13426502 ...,  0.06340556 -0.1886238\n",
      "   0.01122489]\n",
      " [ 0.06979986 -0.08174054 -0.0568376  ...,  0.04328896 -0.155077\n",
      "   1.75352585]\n",
      " [-0.02668688 -0.06067537  0.53500485 ..., -0.09523957  0.01341355\n",
      "   1.80642748]]\n",
      " ===== printing paramter: b1 ===== \n",
      "[[ 0.13687319  0.17148703  0.69647878  1.75060809  0.22554955 -0.0064162\n",
      "  -0.0184671  -0.24005878  0.00568217  0.8563655   0.23870921 -0.29065374\n",
      "   0.17701834 -0.28736883 -0.7496897  -0.14680375 -0.13777561 -0.22236285\n",
      "   0.05340073 -0.21950448  0.58757567  0.20932561  1.98077786  0.0311892\n",
      "  -0.03346266 -0.11549847  0.03857461 -0.21707445 -0.01456001  0.90722561\n",
      "  -2.13461113 -0.75945801 -1.78550851  0.82460248  0.09916598 -0.90579152\n",
      "   0.21888503 -0.15578601  0.09826031 -0.14759701  0.11455441 -0.01027551\n",
      "   2.09978795 -0.23110932  0.2585597   0.21885037  0.17419869  0.14655173\n",
      "  -0.20838152  0.09218395 -0.10508348  0.83441991  0.20921668 -0.00639179\n",
      "  -0.08305596 -1.00351059  0.1095348  -0.03247124  0.05970433  0.0780407\n",
      "  -0.24636836  0.13756457 -0.08918247 -0.19076183 -0.02166271 -0.8275488\n",
      "   0.00632507  0.07047081  0.1113776   0.23781842 -0.15508422  0.01934866\n",
      "   0.16854849 -2.03269362 -0.03828563  1.27750325 -0.23667207 -0.18786973\n",
      "   1.98043132]]\n",
      " ===== printing paramter: W2_1 ===== \n",
      "[[  3.33816916e-01]\n",
      " [  1.36356831e-01]\n",
      " [  2.43870378e-01]\n",
      " [  9.27413988e-04]\n",
      " [  1.09346345e-01]\n",
      " [ -1.43763453e-01]\n",
      " [ -2.19639614e-02]\n",
      " [  3.04999924e+00]\n",
      " [  6.65651858e-02]\n",
      " [ -3.91194224e-03]\n",
      " [  2.87218988e-01]\n",
      " [ -1.11604556e-01]\n",
      " [ -3.03706259e-01]\n",
      " [  9.48012173e-02]\n",
      " [  2.07673490e-01]\n",
      " [ -2.63090163e-01]\n",
      " [  2.06208348e-01]\n",
      " [ -1.80283248e-01]\n",
      " [ -2.93109447e-01]\n",
      " [  1.54309630e-01]\n",
      " [  1.46588326e-01]\n",
      " [ -1.40121922e-01]\n",
      " [ -1.83752477e-01]\n",
      " [ -5.04435897e-02]\n",
      " [ -2.42155924e-01]\n",
      " [ -4.82445061e-02]\n",
      " [  7.89219141e-03]\n",
      " [ -2.73755074e-01]\n",
      " [  4.82209027e-02]\n",
      " [ -9.20683295e-02]\n",
      " [  1.81924522e-01]\n",
      " [  2.47912645e-01]\n",
      " [  2.85911500e-01]\n",
      " [ -1.64748117e-01]\n",
      " [  1.43802464e-01]\n",
      " [  2.34588385e-01]\n",
      " [  2.77402997e-02]\n",
      " [  2.82362342e-01]\n",
      " [ -1.89830899e-01]\n",
      " [  2.64611304e-01]\n",
      " [  2.20568478e-01]\n",
      " [  4.72953022e-02]\n",
      " [  1.78688258e-01]\n",
      " [  9.58612561e-03]\n",
      " [  1.02572680e-01]\n",
      " [  3.31576467e-02]\n",
      " [  2.03575134e-01]\n",
      " [ -1.98973119e-01]\n",
      " [  9.50732827e-02]\n",
      " [ -9.72243845e-02]\n",
      " [ -2.73980260e-01]\n",
      " [ -1.10217527e-01]\n",
      " [  1.16249740e-01]\n",
      " [  2.47378051e-01]\n",
      " [  3.21474075e-01]\n",
      " [  2.32860163e-01]\n",
      " [  4.58871685e-02]\n",
      " [ -4.59330231e-01]\n",
      " [ -4.93214041e-01]\n",
      " [ -3.54674459e-02]\n",
      " [ -9.60324833e-04]]\n",
      " ===== printing paramter: W2_2 ===== \n",
      "[[ -1.81038320e-01]\n",
      " [ -1.85704321e-01]\n",
      " [  3.04802150e-01]\n",
      " [ -1.66571605e+00]\n",
      " [ -1.59739077e-01]\n",
      " [  5.56683987e-02]\n",
      " [ -2.49775127e-01]\n",
      " [ -1.18146546e-01]\n",
      " [  1.66695386e-01]\n",
      " [  9.30079520e-02]\n",
      " [ -2.00534135e-01]\n",
      " [  2.60881279e-02]\n",
      " [ -1.52657270e-01]\n",
      " [ -1.00202060e+00]\n",
      " [ -4.97798353e-01]\n",
      " [ -7.68049732e-02]\n",
      " [ -4.53725755e-02]\n",
      " [  4.16269228e-02]\n",
      " [ -3.66294414e-01]\n",
      " [  2.40183651e-01]\n",
      " [  1.73492819e-01]\n",
      " [  1.99483633e-01]\n",
      " [  1.33802056e-01]\n",
      " [  2.06851304e-01]\n",
      " [ -1.14606947e-01]\n",
      " [  1.59115911e-01]\n",
      " [ -6.73852682e-01]\n",
      " [  2.09876597e-02]\n",
      " [  3.93256592e-03]\n",
      " [  2.38760397e-01]\n",
      " [ -1.89198300e-01]\n",
      " [ -6.30752265e-01]\n",
      " [ -1.16403967e-01]\n",
      " [  8.53191614e-02]\n",
      " [ -1.93640709e-01]\n",
      " [  4.14185464e-01]\n",
      " [ -3.56203169e-02]\n",
      " [ -1.73160836e-01]\n",
      " [ -2.65002638e-01]\n",
      " [  1.47656405e+00]\n",
      " [ -1.00735724e-02]\n",
      " [ -2.00575590e-03]\n",
      " [ -1.26206255e+00]\n",
      " [  4.31252837e-01]\n",
      " [ -2.29623690e-01]\n",
      " [  4.00821865e-02]\n",
      " [ -3.26730996e-01]\n",
      " [ -1.19020484e-01]\n",
      " [  5.21979183e-02]\n",
      " [  2.32781768e-01]\n",
      " [  1.40278965e-01]\n",
      " [  4.32450436e-02]\n",
      " [ -2.73148447e-01]\n",
      " [ -3.36600989e-02]\n",
      " [  8.17259401e-02]\n",
      " [  8.68587121e-02]\n",
      " [ -1.64684355e-01]\n",
      " [  1.11448050e-01]\n",
      " [  1.25419766e-01]\n",
      " [  1.22124457e+00]\n",
      " [  5.31361401e-02]\n",
      " [ -9.97697562e-02]\n",
      " [  1.42760485e-01]\n",
      " [  7.84369409e-02]\n",
      " [ -6.28681630e-02]\n",
      " [ -2.14106157e-01]\n",
      " [  9.37047228e-02]\n",
      " [ -2.08912358e-01]\n",
      " [ -6.94034547e-02]\n",
      " [ -3.12658161e-01]\n",
      " [ -8.83209854e-02]\n",
      " [  1.00811529e+00]\n",
      " [ -2.84144789e-01]\n",
      " [ -1.78060782e+00]\n",
      " [  4.52728420e-02]\n",
      " [  5.71304131e+00]\n",
      " [ -7.24753886e-02]\n",
      " [ -3.68157685e-01]\n",
      " [ -1.08535910e+00]]\n",
      " ===== printing paramter: b2 ===== \n",
      "[[ 0.06405534]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=1500)\n",
    "import pickle\n",
    "para_names=['W1_1', 'W1_2', 'b1', 'W2_1', 'W2_2', 'b2']\n",
    "for i in range(len(para_names)):\n",
    "    print(' ===== printing paramter: '+ para_names[i] +' ===== ')\n",
    "    print(para_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:0, train_loss: -0.034059, test_loss: -1.630274\n",
      "train D prediction parameters results: [ 3.23220277]\n",
      "test D prediction parameters results: [ 3.23220277]\n",
      "train p_f prediction parameters results: [ 0.60555208  0.7045694   0.68091011  0.30111229  0.54585373  0.66564268\n",
      "  0.48729122  0.30588806  0.41609335  0.67593765  0.74941981  0.36908227\n",
      "  0.5547576   0.44096619  0.72063565  0.48429745  0.67054319  0.43081138\n",
      "  0.38840538  0.69923127  0.32507402  0.77526563  0.23774567  0.75146794\n",
      "  0.26140577  0.25591207  0.78756046  0.5877111   0.34113938  0.79413623\n",
      "  0.4544507   0.37690836  0.66596419  0.50433064  0.48565853  0.7569443\n",
      "  0.39516801  0.78460968  0.58200711  0.72888148  0.46899208  0.53185129\n",
      "  0.46412301  0.77735633  0.29954657  0.66114765  0.5456593   0.67107123\n",
      "  0.29962441  0.56004065  0.42768341  0.51264256  0.63848472  0.25395474\n",
      "  0.20880076  0.59493047  0.47163782  0.41734794  0.53167933  0.64431143\n",
      "  0.64578718]\n",
      "test p_f prediction parameters results: [ 0.60555208  0.7045694   0.68091011  0.30111229  0.54585373  0.66564268\n",
      "  0.48729122  0.30588806  0.41609335  0.67593765  0.74941981  0.36908227\n",
      "  0.5547576   0.44096619  0.72063565  0.48429745  0.67054319  0.43081138\n",
      "  0.38840538  0.69923127  0.32507402  0.77526563  0.23774567  0.75146794\n",
      "  0.26140577  0.25591207  0.78756046  0.5877111   0.34113938  0.79413623\n",
      "  0.4544507   0.37690836  0.66596419  0.50433064  0.48565853  0.7569443\n",
      "  0.39516801  0.78460968  0.58200711  0.72888148  0.46899208  0.53185129\n",
      "  0.46412301  0.77735633  0.29954657  0.66114765  0.5456593   0.67107123\n",
      "  0.29962441  0.56004065  0.42768341  0.51264256  0.63848472  0.25395474\n",
      "  0.20880076  0.59493047  0.47163782  0.41734794  0.53167933  0.64431143\n",
      "  0.64578718]\n",
      "iter:100, train_loss: -32854.246094, test_loss: -33637.652344\n",
      "train D prediction parameters results: [ 660.60137939]\n",
      "test D prediction parameters results: [ 661.03363037]\n",
      "train p_f prediction parameters results: [ 69.63760376  69.69882965  69.70024872  69.21742249  69.52993011\n",
      "  67.79338074  69.38115692  69.39240265  69.37909698  69.58930969\n",
      "  69.77483368  68.51525116 -68.8114624   69.41661072  69.73088837\n",
      " -68.91017914  69.67967224  65.58140564 -68.98827362  69.69602966\n",
      "  69.3192215   68.04045868  65.04239655  69.60391235 -68.78621674\n",
      "  69.10958099  69.7125473  -68.81715393  69.29246521  69.39287567\n",
      "  69.4577713   69.3937149   69.69309998  66.66691589  69.47797394\n",
      "  69.7728653   69.33209991  69.80691528  64.74882507  69.75076294\n",
      "  69.4837265   69.48648071  69.46772003  69.70118713  69.28134918\n",
      "  69.60699463  69.55467224  63.1210289   69.27574158  69.05783844\n",
      " -68.98168945  68.71231079  69.62176514  69.27288055  69.2378006\n",
      "  69.61050415  69.42139435 -68.80773163 -68.68035126  69.51833344\n",
      "  69.56060028]\n",
      "test p_f prediction parameters results: [ 69.63760376  69.69882965  69.70024872  69.21742249  69.52993011\n",
      "  67.79338074  69.38115692  69.39240265  69.37909698  69.58930969\n",
      "  69.77483368  68.51525116 -68.8114624   69.41661072  69.73088837\n",
      " -68.91017914  69.67967224  65.58140564 -68.98827362  69.69602966\n",
      "  69.3192215   68.04045868  65.04239655  69.60391235 -68.78621674\n",
      "  69.10958099  69.7125473  -68.81715393  69.29246521  69.39287567\n",
      "  69.4577713   69.3937149   69.69309998  66.66691589  69.47797394\n",
      "  69.7728653   69.33209991  69.80691528  64.74882507  69.75076294\n",
      "  69.4837265   69.48648071  69.46772003  69.70118713  69.28134918\n",
      "  69.60699463  69.55467224  63.1210289   69.27574158  69.05783844\n",
      " -68.98168945  68.71231079  69.62176514  69.27288055  69.2378006\n",
      "  69.61050415  69.42139435 -68.80773163 -68.68035126  69.51833344\n",
      "  69.56060028]\n",
      "iter:200, train_loss: -159958.406250, test_loss: -161730.859375\n",
      "train D prediction parameters results: [ 1445.89941406]\n",
      "test D prediction parameters results: [ 1446.95996094]\n",
      "train p_f prediction parameters results: [ 152.52334595  152.55493164  152.57289124  152.02940369  152.37568665\n",
      "  150.32185364  152.18177795  152.32154846  152.21659851  152.39794922\n",
      "  152.65330505  151.18016052 -152.06811523  152.26481628  152.60127258\n",
      " -152.39978027  152.55302429  147.60491943 -152.29324341  152.56072998\n",
      "  152.17927551  150.59294128  146.97796631  152.36297607 -152.67602539\n",
      "  151.88026428  152.52203369 -152.21803284  152.1234436   152.08534241\n",
      "  152.3274231   152.27256775  152.57066345  149.01919556  152.33985901\n",
      "  152.64720154  152.1552124   152.68843079  146.37702942  152.62930298\n",
      "  152.3543396   152.31785583  152.33123779  152.51481628  152.12347412\n",
      "  152.43321228  152.42758179  143.94506836  152.12188721  151.75778198\n",
      " -152.36303711  151.36309814  152.47573853  152.14764404  152.12437439\n",
      "  152.48603821  152.25248718 -151.86125183 -151.71566772  152.30430603\n",
      "  152.36726379]\n",
      "test p_f prediction parameters results: [ 152.52334595  152.55493164  152.57289124  152.02940369  152.37568665\n",
      "  150.32185364  152.18177795  152.32154846  152.21659851  152.39794922\n",
      "  152.65330505  151.18016052 -152.06811523  152.26481628  152.60127258\n",
      " -152.39978027  152.55302429  147.60491943 -152.29324341  152.56072998\n",
      "  152.17927551  150.59294128  146.97796631  152.36297607 -152.67602539\n",
      "  151.88026428  152.52203369 -152.21803284  152.1234436   152.08534241\n",
      "  152.3274231   152.27256775  152.57066345  149.01919556  152.33985901\n",
      "  152.64720154  152.1552124   152.68843079  146.37702942  152.62930298\n",
      "  152.3543396   152.31785583  152.33123779  152.51481628  152.12347412\n",
      "  152.43321228  152.42758179  143.94506836  152.12188721  151.75778198\n",
      " -152.36303711  151.36309814  152.47573853  152.14764404  152.12437439\n",
      "  152.48603821  152.25248718 -151.86125183 -151.71566772  152.30430603\n",
      "  152.36726379]\n",
      "iter:300, train_loss: -384422.406250, test_loss: -387216.375000\n",
      "train D prediction parameters results: [ 2235.24023438]\n",
      "test D prediction parameters results: [ 2235.61206055]\n",
      "train p_f prediction parameters results: [ 235.90400696  235.91810608  235.94004822  235.35006714  235.72102356\n",
      "  233.37216187  235.50918579  235.73010254  235.54490662  235.72692871\n",
      "  236.01950073  234.3611145  -235.73530579  235.60516357  235.96958923\n",
      " -236.19419861  235.92657471  230.37649536 -235.96490479  235.92533875\n",
      "  235.52487183  233.67152405  229.53442383  235.62657166 -236.90087891\n",
      "  235.15216064  235.84259033 -236.02049255  235.45031738  235.31480408\n",
      "  235.69230652  235.6449585   235.9392395   231.9458313   235.69126892\n",
      "  236.01275635  235.46574402  236.05400085  228.93130493  235.99717712\n",
      "  235.71832275  235.66329956  235.6829834   235.81993103  235.45339966\n",
      "  235.77604675  235.79772949  225.83003235  235.4584198   234.97410583\n",
      " -236.05447388  234.58486938  235.8203125   235.509552    235.50410461\n",
      "  235.85540771  235.57069397 -235.36976624 -235.19902039  235.61022949\n",
      "  235.66635132]\n",
      "test p_f prediction parameters results: [ 235.90400696  235.91810608  235.94004822  235.35006714  235.72102356\n",
      "  233.37216187  235.50918579  235.73010254  235.54490662  235.72692871\n",
      "  236.01950073  234.3611145  -235.73530579  235.60516357  235.96958923\n",
      " -236.19419861  235.92657471  230.37649536 -235.96490479  235.92533875\n",
      "  235.52487183  233.67152405  229.53442383  235.62657166 -236.90087891\n",
      "  235.15216064  235.84259033 -236.02049255  235.45031738  235.31480408\n",
      "  235.69230652  235.6449585   235.9392395   231.9458313   235.69126892\n",
      "  236.01275635  235.46574402  236.05400085  228.93130493  235.99717712\n",
      "  235.71832275  235.66329956  235.6829834   235.81993103  235.45339966\n",
      "  235.77604675  235.79772949  225.83003235  235.4584198   234.97410583\n",
      " -236.05447388  234.58486938  235.8203125   235.509552    235.50410461\n",
      "  235.85540771  235.57069397 -235.36976624 -235.19902039  235.61022949\n",
      "  235.66635132]\n",
      "iter:400, train_loss: -702261.812500, test_loss: -705886.312500\n",
      "train D prediction parameters results: [ 3016.83154297]\n",
      "test D prediction parameters results: [ 3017.06054688]\n",
      "train p_f prediction parameters results: [ 318.4750061   318.46105957  318.50863647  317.8727417   318.27642822\n",
      "  315.76699829  317.99499512  318.33633423  318.09738159  318.23373413\n",
      "  318.59899902  316.81835938 -318.53411865  318.15899658  318.53451538\n",
      " -319.2182312   318.4866333   312.33752441 -318.82131958  318.47579956\n",
      "  318.09152222  316.07092285  311.58679199  318.13223267 -320.00900269\n",
      "  317.6541748   318.36990356 -318.91650391  318.00091553  317.76400757\n",
      "  318.25253296  318.21575928  318.51046753  314.21688843  318.25375366\n",
      "  318.58346558  318.01959229  318.63702393  310.56005859  318.56784058\n",
      "  318.28353882  318.18515015  318.25570679  318.36383057  318.0177002\n",
      "  318.29119873  318.35690308  306.85256958  318.01705933  317.42993164\n",
      " -319.02908325  316.98599243  318.3817749   318.08349609  318.07696533\n",
      "  318.42102051  318.12435913 -318.04986572 -317.8838501   318.10821533\n",
      "  318.20654297]\n",
      "test p_f prediction parameters results: [ 318.4750061   318.46105957  318.50863647  317.8727417   318.27642822\n",
      "  315.76699829  317.99499512  318.33633423  318.09738159  318.23373413\n",
      "  318.59899902  316.81835938 -318.53411865  318.15899658  318.53451538\n",
      " -319.2182312   318.4866333   312.33752441 -318.82131958  318.47579956\n",
      "  318.09152222  316.07092285  311.58679199  318.13223267 -320.00900269\n",
      "  317.6541748   318.36990356 -318.91650391  318.00091553  317.76400757\n",
      "  318.25253296  318.21575928  318.51046753  314.21688843  318.25375366\n",
      "  318.58346558  318.01959229  318.63702393  310.56005859  318.56784058\n",
      "  318.28353882  318.18515015  318.25570679  318.36383057  318.0177002\n",
      "  318.29119873  318.35690308  306.85256958  318.01705933  317.42993164\n",
      " -319.02908325  316.98599243  318.3817749   318.08349609  318.07696533\n",
      "  318.42102051  318.12435913 -318.04986572 -317.8838501   318.10821533\n",
      "  318.20654297]\n"
     ]
    }
   ],
   "source": [
    "#load and save the parameters from last nn, \n",
    "\n",
    "\n",
    "#build nn\n",
    "\n",
    "\n",
    "#optimize the loss funciton by adding negative sign\n",
    "tf.reset_default_graph()\n",
    "p_f = tf.get_variable('p_f', shape=(1, 61)) #x2\n",
    "#p_f = tf.placeholder(shape=(None, 61), dtype=tf.float32) #x2\n",
    "#W2_1 = tf.get_variable('W2_1', shape=(61, 1))\n",
    "#W1_1 = tf.placeholder(shape=(18, 79), dtype=tf.float32)\n",
    "W1_1 = tf.constant(paras[0], dtype=tf.float32, name='W1_1' )\n",
    "#W1_2 = tf.placeholder(shape=(61, 79), dtype=tf.float32)\n",
    "W1_2 = tf.constant(paras[1], dtype=tf.float32, name='W1_2' )\n",
    "#b1 = tf.placeholder(shape=(1, 79), dtype=tf.float32)\n",
    "b1 = tf.constant(paras[2], dtype=tf.float32, name='b1' )\n",
    "#W2_1 =tf.placeholder(shape=(61, 1), dtype=tf.float32)\n",
    "W2_1 = tf.constant(paras[3], dtype=tf.float32, name='W2_1' )\n",
    "#W2_2 = tf.placeholder(shape=(79, 1), dtype=tf.float32)\n",
    "W2_2 = tf.constant(paras[4], dtype=tf.float32, name='W2_2' )\n",
    "#b2 = tf.placeholder(shape=(1, 1), dtype=tf.float32)\n",
    "b2 = tf.constant(paras[5], dtype=tf.float32, name='b2' )\n",
    "p_sub =  tf.placeholder(shape=(None, 18), dtype=tf.float32)\n",
    "#p_sub =  tf.get_variable('p_sub', shape=(1, 18))\n",
    "D = tf.matmul(tf.nn.sigmoid(tf.matmul(p_f, W1_2) + tf.matmul(p_sub, W1_1)+b1), W2_2)+tf.matmul(p_f, W2_1)+b2\n",
    "#print(D)\n",
    "\n",
    "p_loss = tf.reduce_mean(-p_f*D) #self defined loss\n",
    "\n",
    "###parameters\n",
    "#loss_new_price = tf.reduce_mean(losses)\n",
    "batch_size = 50\n",
    "learning_rate = 0.5\n",
    "trainer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "gradients = trainer.compute_gradients(p_loss)\n",
    "optimizer = trainer.apply_gradients(gradients)\n",
    "\n",
    "# train\n",
    "#c_train = np.ones(( , 61)) #(bs, 61)\n",
    "#y_train = tv_train.iloc[step:step+batch_size, 2].values #(bs,)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #saver = tf.train.Saver([p_sub])\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(493):\n",
    "        #parameters \n",
    "        #x1_train = np.concatenate((tv_train.iloc[step:step+batch_size, 3:11].values, tv_train.iloc[step:step+batch_size, 14:67].values), 1)\n",
    "        x1_train = tv_train.iloc[step:step+batch_size, 66:84].values \n",
    "        x1_test = tv_test.iloc[step:step+batch_size, 66:84].values\n",
    "\n",
    "#         W1_1 = [l.tolist() for l in paras[0]]\n",
    "#         W1_2 = [l.tolist() for l in paras[1]]\n",
    "#         b1 = [l.tolist() for l in paras[2]]\n",
    "#         W2_1 = [l.tolist() for l in paras[3]]\n",
    "#         W2_2 = [l.tolist() for l in paras[4]]\n",
    "#         b2 = [l.tolist() for l in paras[5]]\n",
    "        \n",
    "        loss_tr, _ = sess.run([p_loss, optimizer], feed_dict={p_sub: x1_train})\n",
    "        _test_loss = sess.run([p_loss], feed_dict={p_sub: x1_test})\n",
    "        \n",
    "        # predict\n",
    "        D_pred_tr = sess.run([D], feed_dict={p_sub:x1_train})\n",
    "        D_pred_te = sess.run([D], feed_dict={p_sub:x1_test})\n",
    "        pf_pred_tr = sess.run([p_f], feed_dict={p_sub:x1_train})\n",
    "        pf_pred_te = sess.run([p_f], feed_dict={p_sub:x1_test})\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(\"iter:%d, train_loss: %f, test_loss: %f\"%(step, loss_tr,  _test_loss[0]))\n",
    "            print('train D prediction parameters results:', D_pred_tr[0][0])\n",
    "            print('test D prediction parameters results:', D_pred_te[0][0])\n",
    "            print('train p_f prediction parameters results:', pf_pred_tr[0][0])\n",
    "            print('test p_f prediction parameters results:', pf_pred_te[0][0])\n",
    "        # save to disk ...\n",
    "        # saver...\n",
    "        \n",
    "        # predict change to predict / save Price!\n",
    "        #D_predict = sess.run([layer2_out], feed_dict={input1:X1_test,input2:X2_test})\n",
    "        \n",
    "        \n",
    "        ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try process into dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>SalesQuantity</th>\n",
       "      <th>SalesQuantityLag1</th>\n",
       "      <th>SalesQuantityLag7</th>\n",
       "      <th>SalesQuantityLag14</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>InventoryAvailability</th>\n",
       "      <th>WeekOfYear</th>\n",
       "      <th>...</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2626.270000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2651.693980</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2774.575000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2795.760000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2795.760000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2795.760000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2880.506000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2965.250000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-09</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2772.457500</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-10</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2824.009967</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID       Date  SalesQuantity  SalesQuantityLag1  SalesQuantityLag7  \\\n",
       "0  0 2016-01-01              2                  1                  1   \n",
       "1  0 2016-01-02              6                  2                  1   \n",
       "2  0 2016-01-03              5                  6                  1   \n",
       "3  0 2016-01-04              6                  5                  1   \n",
       "4  0 2016-01-05              2                  6                  1   \n",
       "5  0 2016-01-06              1                  2                  1   \n",
       "6  0 2016-01-07              6                  1                  1   \n",
       "7  0 2016-01-08              2                  6                  2   \n",
       "8  0 2016-01-09              5                  2                  6   \n",
       "9  0 2016-01-10              7                  5                  5   \n",
       "\n",
       "   SalesQuantityLag14        Price  Discount  InventoryAvailability  \\\n",
       "0                   1  2626.270000      1.01                   0.93   \n",
       "1                   1  2651.693980      1.01                   0.93   \n",
       "2                   1  2774.575000      1.01                   0.93   \n",
       "3                   1  2795.760000      1.01                   0.93   \n",
       "4                   1  2795.760000      1.01                   0.93   \n",
       "5                   1  2795.760000      1.01                   0.93   \n",
       "6                   1  2880.506000      1.01                   0.93   \n",
       "7                   1  2965.250000      1.01                   0.93   \n",
       "8                   1  2772.457500      1.01                   0.93   \n",
       "9                   1  2824.009967      1.01                   0.93   \n",
       "\n",
       "   WeekOfYear ...  7  8  9  0  1  2  3  4  5  6  \n",
       "0           1 ...  0  0  0  0  0  0  0  1  0  0  \n",
       "1           1 ...  0  0  0  0  0  0  0  0  1  0  \n",
       "2           1 ...  0  0  0  0  0  0  0  0  0  1  \n",
       "3           2 ...  0  0  0  1  0  0  0  0  0  0  \n",
       "4           2 ...  0  0  0  0  1  0  0  0  0  0  \n",
       "5           2 ...  0  0  0  0  0  1  0  0  0  0  \n",
       "6           2 ...  0  0  0  0  0  0  1  0  0  0  \n",
       "7           2 ...  0  0  0  0  0  0  0  1  0  0  \n",
       "8           2 ...  0  0  0  0  0  0  0  0  1  0  \n",
       "9           2 ...  0  0  0  0  0  0  0  0  0  1  \n",
       "\n",
       "[10 rows x 69 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try process into dummy\n",
    "tv_dummy=tv_info.copy()\n",
    "#process IDs \n",
    "Yfinal=tv_dummy.iloc[:,3]\n",
    "ID=[1138263,1139362,1139363,1141061,1142731,1143640,1144140,\n",
    "        1148001,1148010,1148081,1162466,1162467,1162557,1162558,\n",
    "        1162559,1163152,1163153,1164313,1164961,1164962,1165757,\n",
    "        1166153,1166984,1166998,1167021,1167087,1167847,1167918,\n",
    "        1170236,1170372,1170739,1173299,1174241,1174242,1174243,\n",
    "        1174244,1174275,1174293,1174299,1174313,1174314,1174315,\n",
    "        1174339,1174340,1175687,1175833,1175835,1175950,1177151]\n",
    "\n",
    "for i in range(len(ID)):\n",
    "    #print(tv_dummy['ID']==ID[i])\n",
    "    tv_dummy.loc[tv_dummy['ID']==ID[i], 'ID']=i\n",
    "    \n",
    "tv_dummy['ID'] = tv_dummy['ID'].astype(str)\n",
    "tv_dummy=pd.concat([tv_dummy, pd.get_dummies(tv_dummy.iloc[:, 0])], axis=1)     \n",
    "#print(tv_dummy.columns.tolist())\n",
    "#get dummy of weekday\n",
    "temp_date=tv_dummy['Date'].values\n",
    "tv_dummy['Date']=tv_dummy['Date'].dt.dayofweek\n",
    "tv_dummy['Date'] = tv_dummy['Date'].astype(str)\n",
    "#print(set(tv_dummy['Date'].values))\n",
    "tv_dummy=pd.concat([tv_dummy, pd.get_dummies(tv_dummy['Date'])],  axis=1)\n",
    "tv_dummy['Date']=temp_date\n",
    "\n",
    "tv_dummy.head(10)\n",
    "\n",
    "#get \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In progress: 0\n",
      "In progress: 500\n",
      "In progress: 1000\n",
      "In progress: 1500\n",
      "In progress: 2000\n",
      "In progress: 2500\n",
      "In progress: 3000\n",
      "In progress: 3500\n",
      "In progress: 4000\n",
      "In progress: 4500\n",
      "In progress: 5000\n",
      "In progress: 5500\n",
      "In progress: 6000\n",
      "In progress: 6500\n",
      "In progress: 7000\n",
      "In progress: 7500\n",
      "In progress: 8000\n",
      "In progress: 8500\n",
      "In progress: 9000\n",
      "In progress: 9500\n",
      "In progress: 10000\n",
      "In progress: 10500\n",
      "In progress: 11000\n",
      "In progress: 11500\n",
      "In progress: 12000\n",
      "In progress: 12500\n",
      "In progress: 13000\n",
      "In progress: 13500\n",
      "In progress: 14000\n",
      "In progress: 14500\n",
      "In progress: 15000\n",
      "In progress: 15500\n",
      "In progress: 16000\n",
      "In progress: 16500\n",
      "In progress: 17000\n",
      "In progress: 17500\n",
      "In progress: 18000\n",
      "In progress: 18500\n",
      "In progress: 19000\n",
      "In progress: 19500\n",
      "In progress: 20000\n",
      "In progress: 20500\n",
      "In progress: 21000\n",
      "In progress: 21500\n",
      "In progress: 22000\n",
      "In progress: 22500\n",
      "In progress: 23000\n",
      "In progress: 23500\n",
      "In progress: 24000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6938e9697afe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0musim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtv_dummy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000000000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0musim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtv_dummy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1365\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1368\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1735\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1736\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1737\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1738\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1739\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Too many indexers'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m                 raise ValueError(\"Location based indexing can only have \"\n\u001b[0;32m    206\u001b[0m                                  \u001b[1;34m\"[{types}] types\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1670\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1672\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_valid_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1673\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1674\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_valid_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_is_valid_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1711\u001b[0m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1712\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1713\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1714\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "#get corresponding top 9 substitute price and sale\n",
    "usim=tv_sim.copy()\n",
    "tv_dum_copy=tv_dummy.copy()\n",
    "tv_dummy = tv_dummy.assign(sim0=np.nan, sim1=np.nan, sim2=np.nan, sim3=np.nan, sim4=np.nan, \n",
    "                            sim5=np.nan, sim6=np.nan, sim7=np.nan, sim8=np.nan, sim9=np.nan, \n",
    "                            sim10=np.nan, sim11=np.nan, sim12=np.nan, sim13=np.nan, sim14=np.nan, \n",
    "                            sim15=np.nan, sim16=np.nan, sim17=np.nan)\n",
    "\n",
    "def find_idx(i):\n",
    "    idx = np.array(tv_dummy.index[tv_dummy.iloc[:,1]==tv_dummy.iloc[i,1]].tolist())\n",
    "    index = list(map(int, tv_dummy[tv_dummy.iloc[:,1]==tv_dummy.iloc[i,1]].ID.values))\n",
    "    diff = list(set(ID)-set(index))\n",
    "    return index, idx, diff\n",
    "\n",
    "ID=list(range(NumSKU))\n",
    "\n",
    "for i in range(len(tv_dummy)): #will take a long time!!! \n",
    "#for row in df.itertuples(): or try\n",
    "    if i%500==0: \n",
    "        print('In progress:', i)\n",
    "        \n",
    "    index, idx, diff=find_idx(i)\n",
    "    for di in diff:\n",
    "        usim.iloc[int(tv_dummy.iloc[i, 0]), di] = 10000000000\n",
    "    temp = usim.iloc[int(tv_dummy.iloc[i, 0]),:].values\n",
    "    M = sorted(temp)\n",
    "    I = np.argsort(temp)\n",
    "    for j in range(9):\n",
    "        try:\n",
    "            tv_dummy.iloc[i, 69+j*2: 69+j*2+2]=tv_dummy.iloc[idx[np.array(index==I[j])][0],6:8].values\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "tv_dummy.iloc[0:2, 69:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24697\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "descriptor 'toordinal' requires a 'datetime.date' object but received a 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-50f7fa13f8ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0md\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoordinal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mbinaries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: descriptor 'toordinal' requires a 'datetime.date' object but received a 'Series'"
     ]
    }
   ],
   "source": [
    "for i in range(len(info)):\n",
    "    usim=sim\n",
    "    row,col=np.where(info[:,2]==info[i,2])\n",
    "    index=[info[row,1], row]\n",
    "    diff=setdiff1d(ID,index[:,1])\n",
    "    usim[info[i,1],diff]=10000000000\n",
    "    for j in range(9):\n",
    "        M, I= msort(usim[info[i,1],:],'ascend')\n",
    "        r, c=np.where(index[:,1]==I[j])\n",
    "        info[i,NumVar+NumSKU+5+(j-1)*2:NumVar+NumSKU+5+(j-1)*2+1]=info[index(r,2),7:8]\n",
    "\n",
    "\n",
    "final=info[:,4:end]\n",
    "finalSens=final\n",
    "#     for i in range(3):\n",
    "#         finalSens{i}=(final)\n",
    "\n",
    "for i in range(5):\n",
    "    finalSens[1][:,64+(i-1)*2]=0.95*finalSens[1][:,64+(i-1)*2]\n",
    "    finalSens[2][:,64+(i-1)*2]=1.05*finalSens[2][:,64+(i-1)*2]\n",
    "\n",
    "mu=np.zeros(1,size(final,2))\n",
    "sd=np.zeros(1,size(final,2))\n",
    "                   \n",
    "for i in range(len(final)):\n",
    "    mu[1,i]=mean(finalSens[0][:,i])\n",
    "    sd[1,i]=std(finalSens[0][:,i])\n",
    "\n",
    " \n",
    "    for j in range(3):\n",
    "        for i in range(len(final)):\n",
    "            if np.std(1,i)>0:\n",
    "                finalSens[j][:,i]=(finalSens[j][:,i]-mu[1,i])/np.std(1,i)\n",
    "            if np.std(1,i)==0:\n",
    "                finalSens[j][:,i]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# full original script!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "24697\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-66307911fe12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mYfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#2 or 3?\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNumVar\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mNumVar\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mNumSKU\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNumSKU\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNumSKU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNumSKU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNumSKU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    192\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_has_valid_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m    581\u001b[0m                     \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m                         raise ValueError('Must have equal len keys and value '\n\u001b[0m\u001b[0;32m    584\u001b[0m                                          'when setting with an ndarray')\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Must have equal len keys and value when setting with an ndarray"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "\n",
    "info=tv_info.copy()\n",
    "\n",
    "for y in range(10):   #run ten times\n",
    "    #info = pd.read_excel('Television.xlsx', sheet_name='Main')\n",
    "    #sim = pd.read_excel('Television.xlsx', sheet_name='Similarity')\n",
    "    print(y)\n",
    "    Yfinal=info.iloc[:,3] #2 or 3?\n",
    "    print(len(info))\n",
    "    info.iloc[:,NumVar+1:NumVar+NumSKU-1]=np.zeros((len(info),NumSKU-1))\n",
    "    matrix = np.zeros((NumSKU, NumSKU))\n",
    "    for i in range(NumSKU):\n",
    "        sim[i,i]=1000000\n",
    "        \n",
    "    \n",
    "       \n",
    "    for i in range(len(info.iloc[:,0])):\n",
    "        for j in range(len(ID)):\n",
    "            if info.iloc[i,0]==ID[j]:\n",
    "                info.iloc[i,0]=j\n",
    "\n",
    "    ID=list(range(NumSKU))\n",
    "    \n",
    "    for i in range(len(info)):\n",
    "        for j in range(NumSKU-1): #dummy ids\n",
    "            if info.iloc[i,0]==j:\n",
    "                info[i,NumVar+j]=1\n",
    " \n",
    "    for i in range(len(info)):\n",
    "        d=date.toordinal(info.iloc[:,1])\n",
    "\n",
    "    binaries=np.zeros(len(info,1),6)\n",
    "    \n",
    "    for i in range(6):\n",
    "        for j in range(len(info)):\n",
    "            if d[j]==i:\n",
    "                binaries[j,i]=1\n",
    "            else:\n",
    "                binaries[j,i]=0\n",
    "#feature descriping wether is weekday   #dummy weekdays \n",
    "    info[:,NumVar+NumSKU-1:NumVar+NumSKU+4]=binaries\n",
    "    usim=tv_sim.copy()\n",
    "    \n",
    "    for i in range(len(info)):   #also dummying?   \n",
    "        row,col=np.where(info[:,2]==info[i,2])\n",
    "        index=[info[row,0], row]\n",
    "        diff=setdiff1d(ID,index[:,1])\n",
    "        usim[info[i,0],diff]=10000000000\n",
    "        for j in range(9):\n",
    "            M, I= msort(usim[info[i,0],:],'ascend')\n",
    "            r, c=np.where(index[:,1]==I[j])\n",
    "            info[i,NumVar+NumSKU+5+(j-1)*2:NumVar+NumSKU+5+(j-1)*2+1]=info[index(r,2),7:8]\n",
    "\n",
    "\n",
    "    final=info[:,4:end]  #select processed data from column 4\n",
    "    finalSens=final\n",
    "#     for i in range(3):\n",
    "#         finalSens{i}=(final)\n",
    "\n",
    "    for i in range(5):\n",
    "        finalSens[1][:,64+(i-1)*2]=0.95*finalSens[1][:,64+(i-1)*2]\n",
    "        finalSens[2][:,64+(i-1)*2]=1.05*finalSens[2][:,64+(i-1)*2]\n",
    "\n",
    "    mu=np.zeros(1,size(final,2))\n",
    "    sd=np.zeros(1,size(final,2))\n",
    "                   \n",
    "    for i in range(len(final)):\n",
    "        mu[1,i]=mean(finalSens[0][:,i])\n",
    "        sd[1,i]=std(finalSens[0][:,i])\n",
    "\n",
    " \n",
    "        for j in range(3):\n",
    "            for i in range(len(final)):\n",
    "                if np.std(1,i)>0:\n",
    "                    finalSens[j][:,i]=(finalSens[j][:,i]-mu[1,i])/np.std(1,i)\n",
    "                if np.std(1,i)==0:\n",
    "                    finalSens[j][:,i]=0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
