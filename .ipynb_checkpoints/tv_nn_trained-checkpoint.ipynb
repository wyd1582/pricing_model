{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural network train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import libraries and packages\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "#translate from the matlab code\n",
    "import xlrd\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import InputLayer, Input\n",
    "from tensorflow.python.keras.layers import Reshape, MaxPooling2D\n",
    "from tensorflow.python.keras.layers import Conv2D, Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "#translate from the matlab code\n",
    "import xlrd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "NumSKU=49\n",
    "NumVar=13\n",
    "ID=[1138263,1139362,1139363,1141061,1142731,1143640,1144140,\n",
    "        1148001,1148010,1148081,1162466,1162467,1162557,1162558,\n",
    "        1162559,1163152,1163153,1164313,1164961,1164962,1165757,\n",
    "        1166153,1166984,1166998,1167021,1167087,1167847,1167918,\n",
    "        1170236,1170372,1170739,1173299,1174241,1174242,1174243,\n",
    "        1174244,1174275,1174293,1174299,1174313,1174314,1174315,\n",
    "        1174339,1174340,1175687,1175833,1175835,1175950,1177151]\n",
    "\n",
    "#train data\n",
    "new_tv_info = pd.read_excel('C:/Users/wyd15/Downloads/Television.xlsx', sheet_name='new_tv_info') #processed by matlab\n",
    "tv_sim = pd.read_excel('Television.xlsx', sheet_name='Similarity')\n",
    "#tv_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24697\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>SalesQuantity</th>\n",
       "      <th>SalesQuantityLag1</th>\n",
       "      <th>SalesQuantityLag7</th>\n",
       "      <th>SalesQuantityLag14</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>InventoryAvailability</th>\n",
       "      <th>WeekOfYear</th>\n",
       "      <th>...</th>\n",
       "      <th>Var75</th>\n",
       "      <th>Var76</th>\n",
       "      <th>Var77</th>\n",
       "      <th>Var78</th>\n",
       "      <th>Var79</th>\n",
       "      <th>Var80</th>\n",
       "      <th>Var81</th>\n",
       "      <th>Var82</th>\n",
       "      <th>Var83</th>\n",
       "      <th>Var84</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2626.27000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1779.66000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2329.659900</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2533.055050</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2541.530000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1753.387550</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2651.69398</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1880.51008</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2365.113317</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2555.651667</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2794.132285</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1842.372600</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2774.57500</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1851.69608</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2355.083980</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2725.285017</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2835.449192</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1789.243869</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2795.76000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1876.27505</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2468.837450</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2965.260000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2721.716275</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1905.935100</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2795.76000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1876.27505</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2468.837450</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2626.273333</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3473.720000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1905.925200</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       Date  SalesQuantity  SalesQuantityLag1  SalesQuantityLag7  \\\n",
       "0   1 2016-01-01              2                  1                  1   \n",
       "1   1 2016-01-02              6                  2                  1   \n",
       "2   1 2016-01-03              5                  6                  1   \n",
       "3   1 2016-01-04              6                  5                  1   \n",
       "4   1 2016-01-05              2                  6                  1   \n",
       "\n",
       "   SalesQuantityLag14       Price  Discount  InventoryAvailability  \\\n",
       "0                   1  2626.27000      1.01                   0.93   \n",
       "1                   1  2651.69398      1.01                   0.93   \n",
       "2                   1  2774.57500      1.01                   0.93   \n",
       "3                   1  2795.76000      1.01                   0.93   \n",
       "4                   1  2795.76000      1.01                   0.93   \n",
       "\n",
       "   WeekOfYear  ...         Var75  Var76        Var77  Var78        Var79  \\\n",
       "0           1  ...    1779.66000   1.01  2329.659900   1.01  2533.055050   \n",
       "1           1  ...    1880.51008   1.01  2365.113317   1.01  2555.651667   \n",
       "2           1  ...    1851.69608   1.01  2355.083980   1.01  2725.285017   \n",
       "3           2  ...    1876.27505   1.01  2468.837450   1.01  2965.260000   \n",
       "4           2  ...    1876.27505   1.01  2468.837450   1.01  2626.273333   \n",
       "\n",
       "   Var80        Var81  Var82        Var83  Var84  \n",
       "0   1.01  2541.530000   1.01  1753.387550   1.01  \n",
       "1   1.01  2794.132285   1.01  1842.372600   1.01  \n",
       "2   1.01  2835.449192   1.01  1789.243869   1.01  \n",
       "3   1.01  2721.716275   1.01  1905.935100   1.01  \n",
       "4   1.01  3473.720000   1.01  1905.925200   1.01  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(new_tv_info))\n",
    "new_tv_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training demand neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "iter:0, train_loss: 439657.718750, test_loss: 11641.232422\n",
      "iter:100, train_loss: 103.335350, test_loss: 14929.931641\n",
      "iter:200, train_loss: 104.103279, test_loss: 1664.839722\n",
      "iter:300, train_loss: 68.476646, test_loss: 1019.754822\n",
      "iter:400, train_loss: 0.955416, test_loss: 3.171456\n",
      "\n",
      " last test prediction parameters results: 492 0.608837 2.25422 \n",
      " predicted demand for one batch [array([ 0.70660126,  0.74092782,  1.59566879,  0.99777067,  1.05052197,\n",
      "        5.84805012,  6.19572067,  6.09373856,  0.32151628, -0.06324095,\n",
      "        0.26264298,  0.36434817, -0.05837303,  0.28240812, -0.0395155 ,\n",
      "        0.0872457 ,  0.48355436,  0.4318049 ,  5.35510588,  0.41975105,\n",
      "        0.6329391 ,  0.13143992,  1.0626868 ,  0.24695456,  1.00499713,\n",
      "        0.33834267,  0.33597684,  0.21844375,  0.47033465,  0.67773092,\n",
      "        0.78577077,  0.25235832,  0.73745811,  0.81200683,  0.29848135,\n",
      "        0.35814273,  0.73432124,  0.49548948,  0.37802994,  0.48786569,\n",
      "        0.92579138,  0.8401798 ,  0.94821966,  0.66305566,  0.42812955,\n",
      "        0.76065576,  0.78112876,  0.82326818,  0.34169781,  0.46210194], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "beta=0.0001\n",
    "alpha= 0.11 #learning_rate\n",
    "\n",
    "tf.reset_default_graph()\n",
    "x1=tf.placeholder(shape=(None, 18), dtype=tf.float32)\n",
    "x2=tf.placeholder(shape=(None, 61), dtype=tf.float32)\n",
    "y =tf.placeholder(shape=(None, ), dtype=tf.float32)\n",
    "\n",
    "#\n",
    "W1_1 = tf.get_variable('W1_1', shape=(18, 79))\n",
    "W1_2 = tf.get_variable('W1_2', shape=(61, 79))\n",
    "b1 = tf.get_variable('b1', shape=(1, 79))\n",
    "    \n",
    "o1_1 = tf.matmul(x1, W1_1)\n",
    "o1_2 = tf.matmul(x2, W1_2)\n",
    "o1 = o1_1 + o1_2 + b1\n",
    "o1 = tf.nn.sigmoid(o1)\n",
    "W2_1 = tf.get_variable('W2_1', shape=(61, 1))\n",
    "W2_2 = tf.get_variable('W2_2', shape=(79, 1))\n",
    "b2 = tf.get_variable('b2', shape=(1, 1))\n",
    "\n",
    "o2_1 = tf.matmul(x2, W2_1)\n",
    "o2_2 = tf.matmul(o1, W2_2)\n",
    "o2 = o2_1 + o2_2 + b2\n",
    "o2 = tf.reshape(o2, (-1, ))\n",
    "saver = tf.train.Saver([W1_1, W1_2, b1, W2_1, W2_2, b2])\n",
    "\n",
    "#add regularization on all the variables \n",
    "loss = tf.losses.mean_squared_error(y, o2)\n",
    "train_var  = tf.trainable_variables() \n",
    "#add l2 regularization exclude all the bias\n",
    "lossL2 = tf.add_n([ tf.nn.l2_loss(v) for v in train_var if 'b' not in v.name ]) * beta #\n",
    "#loss with regularization\n",
    "loss= tf.reduce_mean(tf.losses.mean_squared_error(y, o2)+lossL2) \n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.11) #tuned learning_rate\n",
    "train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "#train-test_split\n",
    "msk = np.random.rand(len(new_tv_info)) < 0.85 #train_test split\n",
    "tv_train = new_tv_info[msk]\n",
    "tv_test = new_tv_info[~msk]\n",
    "batch_size=50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(493):\n",
    "        x1_train = tv_train.iloc[step:step+batch_size, 66:84].values \n",
    "        x2_train = np.concatenate((tv_train.iloc[step:step+batch_size, 3:11].values, tv_train.iloc[step:step+batch_size, 14:67].values), 1) \n",
    "        y_train = tv_train.iloc[step:step+batch_size, 2].values \n",
    "            \n",
    "        x1_test = tv_test.iloc[step:step+batch_size, 66:84].values \n",
    "        x2_test = np.concatenate((tv_test.iloc[step:step+batch_size, 3:11].values, tv_test.iloc[step:step+batch_size, 14:67].values), 1) \n",
    "        y_test = tv_test.iloc[step:step+batch_size, 2].values \n",
    "            \n",
    "        _train_loss, _ = sess.run([loss, train_op],feed_dict={x1: x1_train,\n",
    "                                              x2: x2_train,\n",
    "                                              y: y_train})\n",
    "            \n",
    "        _test_loss= sess.run([loss],feed_dict={x1: x1_test,\n",
    "                                              x2: x2_test,\n",
    "                                              y: y_test})\n",
    "        # predict\n",
    "        D_predict = sess.run([o2], feed_dict={x1:x1_test,x2:x2_test})\n",
    "        para_pred = sess.run([W1_1, W1_2, b1, W2_1, W2_2, b2], feed_dict={x1:x1_test,x2:x2_test})\n",
    "        #results, _ = sess.run([output]) #print parameters, W1_1 etc..\n",
    "            \n",
    "        if step % 100==0:\n",
    "            saver.save(sess, 'C:/Users/wyd15/Desktop/tv_model/tv_modelslack.ckpt', global_step=step)\n",
    "            print(\"iter:%d, train_loss: %f, test_loss: %f\"%(step, _train_loss,  _test_loss[0]))\n",
    "            #print('test prediction parameters results:', D_predict)\n",
    "            #print('predicted parameters:', para_pred)\n",
    "    print('\\n last test prediction parameters results:', step, _train_loss,  _test_loss[0], '\\n predicted demand for one batch', D_predict)\n",
    "    paras=para_pred\n",
    "                #print('output:', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters for TV NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===== printing paramter: W1_1 ===== \n",
      "[[ -5.14255524e-01   7.86028087e-01   7.38471091e-01  -2.36192588e-02\n",
      "   -6.83786988e-01   7.31086910e-01  -5.36739886e-01  -5.69601297e-01\n",
      "    7.48214312e-03  -6.31047726e-01  -5.90377033e-01  -4.16622281e-01\n",
      "    6.04758143e-01  -1.05506837e+00   6.70666993e-01  -6.16332054e-01\n",
      "   -5.58004320e-01   6.59086943e-01  -5.15469611e-01   5.64842105e-01\n",
      "    6.09208941e-01  -6.16576076e-01  -6.07670605e-01  -5.96234977e-01\n",
      "   -5.20680726e-01  -7.12835312e-01   5.07984698e-01   6.11732602e-01\n",
      "   -6.49068058e-01   5.68380117e-01   5.69340289e-01  -5.23065448e-01\n",
      "   -5.39714038e-01   1.13150907e+00  -5.54871619e-01  -5.66139519e-01\n",
      "   -5.45974672e-01  -6.02915347e-01   5.65338671e-01  -4.33128234e-03\n",
      "    6.24436557e-01   6.67779803e-01   6.66112363e-01  -5.48559308e-01\n",
      "   -6.30786300e-01  -5.61028123e-01  -5.01552045e-01   5.46571076e-01\n",
      "    5.38203657e-01   5.99552274e-01  -5.78354895e-01   6.28229856e-01\n",
      "   -1.04379533e-02  -3.63894994e-03   6.16320431e-01  -6.69015408e-01\n",
      "   -6.68941259e-01   4.85824764e-01   6.14082456e-01  -6.33348465e-01\n",
      "   -8.40076923e-01   6.12515092e-01  -9.35482919e-01  -6.28834367e-01\n",
      "   -5.82148254e-01   6.67569637e-01   5.94162941e-01   6.95217133e-01\n",
      "   -6.37592673e-01  -5.85862160e-01   5.91770053e-01  -5.43817878e-01\n",
      "   -8.63729939e-02  -5.04594982e-01  -1.25451786e-02   5.67040503e-01\n",
      "    5.57776392e-01   5.82073927e-01  -6.17892921e-01]\n",
      " [ -5.50959349e-01   3.73198271e-01   4.13854897e-01  -2.99071423e-13\n",
      "   -5.09832740e-01   6.55743539e-01  -4.76640707e-07  -4.17135328e-01\n",
      "   -1.18763723e-12  -1.16345871e-06  -4.72391814e-01  -7.75396228e-01\n",
      "   -1.11520498e-11  -8.71659257e-04   6.59085155e-01  -4.96831208e-01\n",
      "   -1.41347549e-03   5.22964418e-01  -2.48869578e-03   2.64881107e-12\n",
      "    2.56132990e-01  -4.34198588e-01  -5.28112769e-01  -5.86746633e-01\n",
      "   -4.93570417e-01  -5.95722556e-01   5.95384359e-01   5.30853927e-01\n",
      "   -4.89619344e-01   2.94488273e-04   4.09246504e-01  -4.81301159e-01\n",
      "   -6.66905997e-09   3.96585107e-01  -1.38773136e-02  -5.86127400e-01\n",
      "   -5.56516111e-01  -5.64525664e-01   4.21751410e-01   9.46109058e-09\n",
      "    3.84820014e-01   7.13256821e-02   3.59156847e-01  -4.53059673e-01\n",
      "   -5.83252847e-01  -3.48768532e-02  -6.11207485e-01   5.32119095e-01\n",
      "    4.61545020e-01   1.06317530e-04  -6.46289089e-04   1.91892549e-01\n",
      "   -3.04438170e-13  -5.97022486e-13   4.08747008e-10  -5.31937659e-01\n",
      "   -6.13444090e-01   1.32216558e-01   5.98609507e-01  -5.45937896e-01\n",
      "    9.75902258e-12   3.63715112e-01  -6.15867317e-01  -5.12263417e-01\n",
      "   -6.41518950e-01   6.56593978e-01   6.06179118e-01   5.32352269e-01\n",
      "   -1.47232264e-01  -2.90899128e-01   6.46495819e-01  -5.19044042e-01\n",
      "   -1.52345735e-03  -3.47465612e-02   5.48013512e-13   6.47050560e-01\n",
      "    7.20608756e-02   5.76682568e-01  -4.79310676e-02]\n",
      " [ -4.93254662e-01   8.99100065e-01   7.42096364e-01  -5.71658537e-02\n",
      "   -5.10826349e-01   7.28600562e-01  -6.65177822e-01  -5.05209506e-01\n",
      "    5.13729341e-02  -4.80533510e-01  -6.25593901e-01  -7.51394808e-01\n",
      "    5.53749859e-01  -1.15767229e+00   6.16789877e-01  -5.26232541e-01\n",
      "   -5.65810084e-01   7.35589445e-01  -4.78959620e-01   5.51449239e-01\n",
      "    6.48693502e-01  -5.49464524e-01  -6.33162558e-01  -5.79655349e-01\n",
      "   -6.07860804e-01  -6.82080328e-01   6.14519477e-01   5.25046468e-01\n",
      "   -5.05812764e-01   4.96317714e-01   6.61191225e-01  -6.89151943e-01\n",
      "   -6.53614938e-01   1.15533900e+00  -7.67229259e-01  -5.19052148e-01\n",
      "   -6.50859594e-01  -5.86806774e-01   5.80773473e-01  -6.35562511e-03\n",
      "    6.18620574e-01   6.51671112e-01   6.55557573e-01  -5.73456705e-01\n",
      "   -6.44704878e-01  -5.55244684e-01  -6.17435873e-01   6.70268476e-01\n",
      "    6.02870882e-01   5.76391280e-01  -5.49841166e-01   5.04384220e-01\n",
      "   -5.74121997e-02  -1.85238253e-02   5.46975672e-01  -5.84135950e-01\n",
      "   -6.36280537e-01   4.79424953e-01   6.56165957e-01  -5.74964106e-01\n",
      "   -4.04115468e-01   5.50380349e-01  -9.78651583e-01  -6.15099192e-01\n",
      "   -6.52427197e-01   6.66967988e-01   5.95852196e-01   5.61786890e-01\n",
      "   -5.16197741e-01  -6.31190300e-01   5.32655299e-01  -6.10927880e-01\n",
      "   -4.24541943e-02  -5.37364006e-01  -5.77245429e-02   6.13127649e-01\n",
      "    6.65571809e-01   6.85769558e-01  -5.51487327e-01]\n",
      " [ -4.90533113e-01   4.91771549e-01   4.13992345e-01  -8.47384175e-13\n",
      "   -4.47133213e-01   6.71810925e-01  -4.96419887e-07  -5.08166432e-01\n",
      "    1.23532022e-12  -1.27165322e-06  -5.17413795e-01  -5.72941184e-01\n",
      "   -8.96108535e-12  -8.71475961e-04   6.31556869e-01  -5.66850781e-01\n",
      "   -1.47094252e-03   5.18477321e-01  -2.28612148e-03   4.62857183e-13\n",
      "    3.05054635e-01  -5.72132766e-01  -5.12548625e-01  -4.80269402e-01\n",
      "   -5.06253719e-01  -6.33114398e-01   5.73232174e-01   5.37425280e-01\n",
      "   -5.86583555e-01   2.90742144e-04   4.68741417e-01  -5.02791107e-01\n",
      "   -7.39702299e-09   3.96472424e-01  -1.13338903e-02  -4.87239838e-01\n",
      "   -5.93890965e-01  -6.19095087e-01   4.81870532e-01   6.04665118e-09\n",
      "    2.87215441e-01   7.07816556e-02   4.03212547e-01  -5.14741361e-01\n",
      "   -6.31998360e-01  -4.62302454e-02  -5.08556008e-01   3.81296933e-01\n",
      "    3.66757810e-01   1.07003383e-04  -6.63758605e-04   2.27734119e-01\n",
      "   -5.21344469e-13   2.93325368e-13   4.12398449e-10  -4.40630138e-01\n",
      "   -6.04331851e-01   1.40365526e-01   6.01057231e-01  -5.30520499e-01\n",
      "    9.68739672e-12   3.95801693e-01  -6.18777156e-01  -5.68170488e-01\n",
      "   -6.13060117e-01   6.60958648e-01   6.46788180e-01   4.65510726e-01\n",
      "   -1.49597034e-01  -2.70209908e-01   5.68844199e-01  -5.25606453e-01\n",
      "    1.06054358e-06  -3.47525440e-02  -8.97847877e-14   6.21328890e-01\n",
      "    5.77755943e-02   5.66754580e-01  -5.50743975e-02]\n",
      " [ -6.47230685e-01   7.50842869e-01   7.46832252e-01  -3.32973339e-02\n",
      "   -4.52549666e-01   7.16921091e-01  -4.84277815e-01  -5.76493263e-01\n",
      "    1.88980866e-02  -6.35238469e-01  -5.97291946e-01  -8.03996146e-01\n",
      "    5.47036171e-01  -1.10971117e+00   6.80746198e-01  -5.15174687e-01\n",
      "   -5.66057146e-01   7.21751928e-01  -6.47399068e-01   5.08295715e-01\n",
      "    6.19729578e-01  -5.22488475e-01  -6.10480249e-01  -5.18269777e-01\n",
      "   -6.17093801e-01  -6.89448714e-01   6.25896811e-01   5.63612401e-01\n",
      "   -6.70821607e-01   5.50450981e-01   5.60056329e-01  -4.31768566e-01\n",
      "   -5.97157657e-01   1.14464879e+00  -4.81179267e-01  -5.51665902e-01\n",
      "   -6.08546615e-01  -6.13496602e-01   5.58456898e-01  -5.83370822e-03\n",
      "    6.26916647e-01   6.52288139e-01   6.83072567e-01  -6.12034023e-01\n",
      "   -5.57236493e-01  -4.59507972e-01  -5.46981156e-01   6.41759574e-01\n",
      "    5.55174947e-01   6.10175669e-01  -6.57207787e-01   6.27323091e-01\n",
      "   -3.00521404e-02  -4.93144616e-03   5.07816374e-01  -5.42271376e-01\n",
      "   -6.47730947e-01   4.88817304e-01   5.35726488e-01  -6.00287795e-01\n",
      "   -6.57617509e-01   5.04303992e-01  -9.53958094e-01  -5.47509909e-01\n",
      "   -6.42048419e-01   6.92393243e-01   5.72440028e-01   4.39428061e-01\n",
      "   -6.34619772e-01  -6.21057510e-01   5.08802116e-01  -5.61947107e-01\n",
      "   -1.12778500e-01  -6.75229251e-01  -1.95894260e-02   6.11280441e-01\n",
      "    5.21708071e-01   5.31870663e-01  -6.83551729e-01]\n",
      " [ -3.88709813e-01   3.78623605e-01   4.05163437e-01  -8.54549721e-13\n",
      "   -5.88798404e-01   6.69910908e-01  -4.80489234e-07  -4.89575297e-01\n",
      "   -9.66323375e-13  -1.24456972e-06  -5.31110585e-01  -5.86544514e-01\n",
      "   -1.02769130e-11  -8.71449127e-04   6.75437033e-01  -6.05476379e-01\n",
      "   -1.53999636e-03   5.10934472e-01  -3.07138311e-03   1.21326126e-13\n",
      "    3.59423369e-01  -5.57117581e-01  -4.99124348e-01  -5.40754318e-01\n",
      "   -5.47718942e-01  -6.01281285e-01   5.93397796e-01   5.51120937e-01\n",
      "   -4.59683746e-01   2.80001201e-04   4.63264257e-01  -4.32132870e-01\n",
      "   -5.30484368e-09   3.99145722e-01  -1.21227643e-02  -5.18597066e-01\n",
      "   -5.21919549e-01  -5.68740666e-01   4.36051816e-01   2.97530711e-09\n",
      "    3.90055925e-01   7.33097866e-02   4.90125030e-01  -5.14052391e-01\n",
      "   -6.14385486e-01  -4.38810252e-02  -6.40255809e-01   4.83697563e-01\n",
      "    4.61546451e-01   9.37609802e-05  -6.97006530e-04   1.89163700e-01\n",
      "   -7.57361730e-13  -5.63620656e-13   3.85965426e-10  -5.29090047e-01\n",
      "   -6.22235239e-01   1.39767423e-01   5.68975389e-01  -5.78026712e-01\n",
      "    9.77078227e-12   3.92559707e-01  -6.17905140e-01  -5.98082960e-01\n",
      "   -6.40173256e-01   6.57953024e-01   5.53269923e-01   3.86515945e-01\n",
      "   -1.59350291e-01  -2.86315680e-01   4.90311235e-01  -5.66311657e-01\n",
      "    7.36525632e-04  -3.33478935e-02   1.01842287e-12   6.19265318e-01\n",
      "    7.66517371e-02   4.86054927e-01  -4.62794714e-02]\n",
      " [ -8.34631264e-01   4.12723839e-01   7.72593617e-01  -1.79094262e-02\n",
      "   -6.83916628e-01   7.13165522e-01  -6.67810857e-01  -5.86958289e-01\n",
      "    8.62842053e-03  -6.53356552e-01  -5.90981483e-01  -4.41765338e-01\n",
      "    5.48535883e-01  -1.05608130e+00   6.32885635e-01  -5.90296447e-01\n",
      "   -6.50285125e-01   6.19100213e-01  -6.07051492e-01   5.35455525e-01\n",
      "    5.23837090e-01  -6.16904497e-01  -5.86501241e-01  -5.94794214e-01\n",
      "   -6.23796046e-01  -7.24401355e-01   5.36436915e-01   6.08280838e-01\n",
      "   -6.70666039e-01   5.51859677e-01   6.04024410e-01  -5.27018249e-01\n",
      "   -4.88076150e-01   1.12933445e+00  -8.21732521e-01  -6.16955638e-01\n",
      "   -6.49792075e-01  -6.20274425e-01   5.98133147e-01  -1.02053490e-02\n",
      "    5.71440399e-01   6.43527925e-01   6.02385461e-01  -6.21592820e-01\n",
      "   -5.75590611e-01  -5.75962067e-01  -5.43856382e-01   6.26031339e-01\n",
      "    5.75509846e-01   5.95547795e-01  -5.04074752e-01   5.41734159e-01\n",
      "   -1.20027866e-02  -3.82428453e-03   5.68556666e-01  -6.16010904e-01\n",
      "   -6.60019755e-01   6.44303083e-01   7.34354734e-01  -5.93096673e-01\n",
      "   -8.05435181e-01   5.33780634e-01  -9.24108863e-01  -6.01562619e-01\n",
      "   -6.26071751e-01   6.64338529e-01   5.90639412e-01   5.72095096e-01\n",
      "   -6.60278440e-01  -6.14238918e-01   5.57071269e-01  -5.83938956e-01\n",
      "   -9.16218981e-02  -6.79117978e-01  -7.18496833e-03   6.10080183e-01\n",
      "    4.36125785e-01   5.28524220e-01  -6.59197927e-01]\n",
      " [ -3.62921625e-01   3.24482590e-01   4.08799529e-01   8.30858060e-13\n",
      "   -4.42769200e-01   7.00510979e-01  -4.57509543e-07  -3.49145174e-01\n",
      "    1.97107088e-13  -1.31969512e-06  -5.11668563e-01  -4.49007869e-01\n",
      "   -1.11468204e-11  -8.70665594e-04   6.62725687e-01  -6.06009007e-01\n",
      "   -1.44521892e-03   5.32755792e-01  -3.06795537e-03   3.38150406e-12\n",
      "    3.28812569e-01  -4.93888557e-01  -5.49616516e-01  -4.95492250e-01\n",
      "   -5.74219525e-01  -6.33665085e-01   6.09371185e-01   6.00574672e-01\n",
      "   -5.27574897e-01   1.32199857e-04   4.57543492e-01  -6.70426190e-01\n",
      "   -7.89306043e-09   3.96633059e-01  -1.48101598e-02  -5.59770048e-01\n",
      "   -5.16947448e-01  -5.84381044e-01   5.29354930e-01   4.54233628e-09\n",
      "    3.28393638e-01   7.37178102e-02   3.96988660e-01  -5.61100602e-01\n",
      "   -5.75449646e-01  -3.99646312e-02  -4.93916869e-01   5.21921396e-01\n",
      "    4.02051240e-01   1.18586417e-04  -6.00839383e-04   2.16260478e-01\n",
      "   -1.11881478e-13  -5.15784410e-13   4.36162356e-10  -4.95647728e-01\n",
      "   -6.40778244e-01   1.64396748e-01   5.53996503e-01  -5.79034507e-01\n",
      "   -4.81947121e-12   3.30934376e-01  -6.15493715e-01  -5.51918387e-01\n",
      "   -6.81419909e-01   6.57058656e-01   5.69173157e-01   5.36303937e-01\n",
      "   -1.55837834e-01  -2.89168656e-01   5.96994162e-01  -5.18321812e-01\n",
      "   -8.29567492e-04  -3.41253318e-02  -9.15497496e-13   6.02057636e-01\n",
      "    8.05879161e-02   5.57585001e-01  -4.32014018e-02]\n",
      " [ -6.19344890e-01   5.62606454e-01   7.57255733e-01  -1.19962320e-02\n",
      "   -6.58389628e-01   7.16359437e-01  -6.35852754e-01  -5.76491594e-01\n",
      "    3.00423242e-03  -6.51021063e-01  -6.10582232e-01  -5.32917738e-01\n",
      "    5.98504961e-01  -1.01664555e+00   6.17190301e-01  -5.30827761e-01\n",
      "   -5.95144987e-01   5.97157538e-01  -5.97451389e-01   5.31879604e-01\n",
      "    6.43171847e-01  -5.15839577e-01  -6.62781060e-01  -6.42123818e-01\n",
      "   -6.20891333e-01  -7.15986371e-01   6.10173345e-01   5.74276984e-01\n",
      "   -6.58308685e-01   6.30394340e-01   6.01276159e-01  -5.99707007e-01\n",
      "   -6.03394389e-01   1.11918128e+00  -4.15752709e-01  -6.57980025e-01\n",
      "   -5.95689952e-01  -6.25408113e-01   5.25193870e-01  -2.23759878e-02\n",
      "    5.42688966e-01   6.86955154e-01   6.82296276e-01  -6.17712736e-01\n",
      "   -5.90170085e-01  -6.82727158e-01  -6.08425081e-01   4.93276656e-01\n",
      "    5.08950353e-01   4.98979151e-01  -5.37255168e-01   5.97979367e-01\n",
      "   -4.50127572e-03  -6.80049823e-04   5.92170894e-01  -4.81612086e-01\n",
      "   -6.53828681e-01   5.66356182e-01   6.49716556e-01  -5.51469505e-01\n",
      "   -8.68725002e-01   6.27047062e-01  -9.20176506e-01  -5.69802046e-01\n",
      "   -6.31592333e-01   6.69894457e-01   6.22094691e-01   5.45662045e-01\n",
      "   -5.82602262e-01  -5.72916210e-01   4.99391794e-01  -5.39816558e-01\n",
      "   -6.68845624e-02  -5.62925100e-01  -4.23542177e-03   6.08576417e-01\n",
      "    6.75913393e-01   5.50611019e-01  -5.42138934e-01]\n",
      " [ -7.38972723e-01   4.40961868e-01   4.02831614e-01  -2.69992362e-13\n",
      "   -6.12698317e-01   6.71061993e-01  -3.95539303e-07  -4.72999305e-01\n",
      "   -1.27847147e-12  -1.31964975e-06  -5.48132241e-01  -4.52371418e-01\n",
      "   -1.01960896e-11  -8.71598197e-04   6.37125611e-01  -5.79529881e-01\n",
      "   -1.49991142e-03   5.18632233e-01  -2.58630724e-03   4.21840731e-13\n",
      "    2.82999128e-01  -5.16359746e-01  -4.64132786e-01  -5.42190909e-01\n",
      "   -5.66049576e-01  -5.74845135e-01   5.73485017e-01   5.76382339e-01\n",
      "   -4.95683312e-01   3.09092284e-04   4.28225100e-01  -6.60902619e-01\n",
      "   -6.72977762e-09   3.96509945e-01  -1.26109794e-02  -5.10210216e-01\n",
      "   -5.75663686e-01  -5.88031232e-01   4.71003413e-01  -3.07352943e-09\n",
      "    2.92862117e-01   7.52769709e-02   3.95231396e-01  -5.06517291e-01\n",
      "   -5.78644872e-01  -4.24448662e-02  -5.56038022e-01   5.21050692e-01\n",
      "    3.61308843e-01   9.08662914e-05  -6.79603079e-04   2.28494927e-01\n",
      "   -1.75688891e-13   1.90761469e-13   3.79368703e-10  -5.07495880e-01\n",
      "   -6.34765029e-01   1.78961709e-01   5.72854996e-01  -6.03056669e-01\n",
      "    1.28506181e-11   3.69090974e-01  -6.15821779e-01  -6.61052823e-01\n",
      "   -6.15736604e-01   6.76226318e-01   5.93662083e-01   4.75564629e-01\n",
      "   -1.36132568e-01  -2.75589049e-01   4.72619146e-01  -5.26614785e-01\n",
      "    4.01921396e-04  -3.09851654e-02  -3.47885810e-13   5.99882126e-01\n",
      "    7.23477155e-02   6.17650032e-01  -4.98154201e-02]\n",
      " [ -5.42060673e-01   5.78480303e-01   7.65530229e-01  -2.12959275e-02\n",
      "   -5.95142424e-01   7.18038917e-01  -4.77604449e-01  -6.06120050e-01\n",
      "    1.36453174e-02  -4.84609067e-01  -6.62680149e-01  -8.64421904e-01\n",
      "    5.84872127e-01  -1.07782507e+00   6.57780588e-01  -6.07684314e-01\n",
      "   -6.57116830e-01   7.10063040e-01  -4.90444273e-01   5.60765028e-01\n",
      "    6.38363600e-01  -6.14235163e-01  -5.38168550e-01  -5.86398840e-01\n",
      "   -5.51118314e-01  -6.66216552e-01   6.61422610e-01   6.76006794e-01\n",
      "   -6.32266223e-01   4.75476921e-01   6.08543396e-01  -5.93480587e-01\n",
      "   -6.93458736e-01   1.13803303e+00  -4.65247899e-01  -5.23376167e-01\n",
      "   -5.18199146e-01  -5.43842971e-01   5.14623761e-01  -1.96200293e-02\n",
      "    5.31596422e-01   6.58087611e-01   5.45048058e-01  -5.39351702e-01\n",
      "   -5.75833023e-01  -6.96536481e-01  -6.07725143e-01   5.49136341e-01\n",
      "    6.13120735e-01   5.40776849e-01  -6.06989801e-01   5.02878726e-01\n",
      "   -1.86666064e-02  -5.90905594e-03   5.33261478e-01  -5.15293896e-01\n",
      "   -6.50278687e-01   6.46364093e-01   5.92009187e-01  -5.60910583e-01\n",
      "   -6.28091097e-01   6.11134827e-01  -9.35389280e-01  -5.62295854e-01\n",
      "   -6.38709605e-01   6.86290383e-01   6.11460865e-01   4.47637588e-01\n",
      "   -5.24733663e-01  -6.46043062e-01   6.12751007e-01  -5.08607090e-01\n",
      "   -1.11154899e-01  -6.25168383e-01  -2.42083017e-02   5.70145428e-01\n",
      "    5.90242386e-01   4.57746536e-01  -6.76415682e-01]\n",
      " [ -3.86338770e-01   3.59898567e-01   3.99973720e-01  -4.62122148e-13\n",
      "   -4.49330360e-01   6.70919418e-01  -4.97415272e-07  -4.77399766e-01\n",
      "    3.85008648e-13  -1.28234467e-06  -5.05009413e-01  -5.44273138e-01\n",
      "   -1.02469509e-11  -8.71611817e-04   6.78595185e-01  -5.91963410e-01\n",
      "   -1.66956906e-03   5.03549397e-01  -3.12898285e-03  -4.49606064e-13\n",
      "    3.22995216e-01  -5.92351556e-01  -5.56646943e-01  -6.04673088e-01\n",
      "   -6.16324127e-01  -5.92501402e-01   5.52036583e-01   6.05232358e-01\n",
      "   -6.02793515e-01   2.71211349e-04   4.20811296e-01  -4.90629286e-01\n",
      "   -7.34227790e-09   3.96749437e-01  -1.21280542e-02  -5.40958941e-01\n",
      "   -5.52670419e-01  -5.36117136e-01   4.61024582e-01   3.77247122e-09\n",
      "    3.71837765e-01   7.32290298e-02   3.81550729e-01  -5.07719278e-01\n",
      "   -5.52695990e-01  -3.06407623e-02  -6.53078437e-01   4.01553959e-01\n",
      "    4.41771358e-01   1.03179380e-04  -6.96585397e-04   2.04138711e-01\n",
      "    3.26489053e-14  -5.03579058e-13   3.79394544e-10  -4.57069427e-01\n",
      "   -6.40149534e-01   1.77314982e-01   5.89220703e-01  -5.29991567e-01\n",
      "    1.20895542e-11   3.95869851e-01  -6.13695741e-01  -6.25152886e-01\n",
      "   -6.82309270e-01   6.47679925e-01   5.73383510e-01   4.54960585e-01\n",
      "   -1.52270049e-01  -2.57973313e-01   5.74407578e-01  -4.66617316e-01\n",
      "    9.35849734e-04  -2.89823785e-02   3.95949739e-13   5.53752899e-01\n",
      "    7.61347935e-02   5.96060574e-01  -5.77169359e-02]\n",
      " [ -8.99400771e-01   4.94451106e-01   7.50181794e-01  -3.47539894e-02\n",
      "   -5.27580023e-01   7.06544757e-01  -6.20728076e-01  -5.32829881e-01\n",
      "    1.49397915e-02  -4.77709979e-01  -6.08171821e-01  -7.75019348e-01\n",
      "    5.50219357e-01  -1.05847824e+00   6.18084133e-01  -6.03731751e-01\n",
      "   -5.14130294e-01   6.28907740e-01  -6.20329440e-01   5.65740943e-01\n",
      "    5.62565267e-01  -5.36834419e-01  -5.86634457e-01  -5.05060494e-01\n",
      "   -5.05249858e-01  -7.17410505e-01   6.04529858e-01   5.69518030e-01\n",
      "   -4.97019947e-01   5.59478402e-01   6.10114455e-01  -6.94095552e-01\n",
      "   -6.18172765e-01   1.13927424e+00  -8.43438208e-01  -5.51254213e-01\n",
      "   -5.80283880e-01  -5.14545739e-01   6.09810412e-01  -1.14085265e-02\n",
      "    5.20010471e-01   6.78426862e-01   4.94623631e-01  -5.07048190e-01\n",
      "   -6.48691475e-01  -5.96354783e-01  -6.21321440e-01   6.46104097e-01\n",
      "    5.48339486e-01   5.26835263e-01  -5.47148407e-01   5.95463872e-01\n",
      "   -2.13969015e-02  -1.01980735e-02   5.45309067e-01  -5.37795842e-01\n",
      "   -6.68706298e-01   6.49477661e-01   6.24702871e-01  -5.19808650e-01\n",
      "   -5.96294940e-01   5.98237216e-01  -9.54190135e-01  -5.83637536e-01\n",
      "   -6.55363142e-01   6.46687508e-01   5.98854542e-01   6.79336011e-01\n",
      "   -5.77389657e-01  -6.02735460e-01   5.81194818e-01  -6.04801714e-01\n",
      "   -8.52729753e-02  -6.00156307e-01  -2.23584380e-02   6.16590261e-01\n",
      "    5.22472799e-01   6.85205162e-01  -6.72170579e-01]\n",
      " [ -6.23459518e-01   4.02984887e-01   4.11927015e-01  -2.37091623e-13\n",
      "   -6.33687079e-01   6.96795404e-01  -4.86366503e-07  -4.23370630e-01\n",
      "   -1.15228454e-12  -1.03354307e-06  -4.93822575e-01  -7.18292356e-01\n",
      "   -9.19562343e-12  -8.71412689e-04   6.32404327e-01  -6.03441477e-01\n",
      "   -1.52609695e-03   4.94572043e-01  -2.45566154e-03  -2.01398728e-12\n",
      "    3.56534630e-01  -5.02200603e-01  -5.08833647e-01  -5.33650756e-01\n",
      "   -5.26336968e-01  -5.95449567e-01   5.51429152e-01   5.55680692e-01\n",
      "   -5.25417089e-01   3.36599594e-04   4.46579605e-01  -4.08487260e-01\n",
      "   -5.51347634e-09   3.96534830e-01  -1.21192439e-02  -5.20008087e-01\n",
      "   -5.54101765e-01  -5.58073342e-01   4.54979688e-01   9.46836742e-09\n",
      "    2.88404793e-01   7.32252672e-02   3.77827018e-01  -4.89118010e-01\n",
      "   -5.73736012e-01  -3.77732441e-02  -5.47162533e-01   5.21634459e-01\n",
      "    4.35205072e-01   1.21041121e-04  -5.99318184e-04   2.21415952e-01\n",
      "    1.22311015e-13  -8.57587547e-13   3.73936937e-10  -5.82920253e-01\n",
      "   -6.37935460e-01   1.29314810e-01   6.23270750e-01  -5.49759865e-01\n",
      "    8.90647799e-12   3.36440384e-01  -6.17852330e-01  -6.30218506e-01\n",
      "   -6.35516465e-01   6.85388923e-01   5.70671499e-01   4.71606016e-01\n",
      "   -1.35987505e-01  -2.63369530e-01   5.65645993e-01  -6.21567786e-01\n",
      "   -8.38195498e-04  -3.37109305e-02  -3.96310209e-13   5.56214869e-01\n",
      "    7.47701898e-02   5.53517401e-01  -5.95211498e-02]\n",
      " [ -8.85264218e-01   6.83521450e-01   7.55683959e-01  -7.58459195e-02\n",
      "   -5.23691297e-01   7.09310710e-01  -5.06986737e-01  -5.52478969e-01\n",
      "    2.18562167e-02  -6.43490732e-01  -6.22127831e-01  -6.31759286e-01\n",
      "    6.17741942e-01  -1.09999609e+00   6.69628680e-01  -6.08299255e-01\n",
      "   -5.65174878e-01   7.03772783e-01  -6.26838386e-01   5.31204879e-01\n",
      "    6.02630496e-01  -6.03422403e-01  -5.56886613e-01  -5.64791441e-01\n",
      "   -5.20805717e-01  -6.86941445e-01   5.38109064e-01   6.09961092e-01\n",
      "   -4.84245569e-01   6.08558178e-01   5.30399024e-01  -5.28680503e-01\n",
      "   -6.02180362e-01   1.15260375e+00  -7.31844902e-01  -5.94182193e-01\n",
      "   -5.15477002e-01  -6.13398135e-01   5.43662310e-01  -7.10045639e-03\n",
      "    6.70368731e-01   6.49805963e-01   4.86618727e-01  -6.31715715e-01\n",
      "   -6.16404831e-01  -5.43429255e-01  -5.58829665e-01   4.80240375e-01\n",
      "    5.16145170e-01   5.43645620e-01  -6.26283169e-01   5.63000917e-01\n",
      "   -3.86538692e-02  -1.09575614e-02   6.28679037e-01  -5.17330170e-01\n",
      "   -6.79506361e-01   6.69537067e-01   5.99253416e-01  -6.62316442e-01\n",
      "   -5.66284060e-01   5.55342197e-01  -9.58767176e-01  -6.17406785e-01\n",
      "   -6.04623258e-01   7.01692283e-01   6.00715160e-01   5.11777043e-01\n",
      "   -5.17289042e-01  -6.05231464e-01   6.03585720e-01  -4.96159196e-01\n",
      "   -1.06425621e-01  -6.73684120e-01  -2.54137702e-02   5.06739497e-01\n",
      "    5.54559350e-01   5.11679590e-01  -5.00609934e-01]\n",
      " [ -5.07776022e-01   3.02158237e-01   4.17493790e-01  -1.29862906e-12\n",
      "   -6.40760720e-01   6.84222937e-01  -4.89468562e-07  -4.69339579e-01\n",
      "    4.06334471e-13  -1.34052266e-06  -4.95072633e-01  -5.38776696e-01\n",
      "   -1.04913378e-11  -8.70444230e-04   6.10960066e-01  -5.26713848e-01\n",
      "   -1.69523724e-03   5.18091023e-01  -2.37302342e-03  -5.85350995e-13\n",
      "    3.71041745e-01  -4.49246794e-01  -5.48029482e-01  -5.35432458e-01\n",
      "   -5.20626962e-01  -5.95098138e-01   5.77440441e-01   5.63854754e-01\n",
      "   -5.62662005e-01   3.37638194e-04   3.93459171e-01  -4.42797631e-01\n",
      "   -6.47936282e-09   4.56380635e-01  -9.16644465e-03  -5.29753506e-01\n",
      "   -5.62710643e-01  -5.21718979e-01   3.54892045e-01   6.36728581e-09\n",
      "    3.69757175e-01   7.02620521e-02   5.11903048e-01  -5.47190249e-01\n",
      "   -6.11869633e-01  -3.84468138e-02  -6.41694188e-01   3.89961243e-01\n",
      "    4.19274092e-01   1.18082877e-04  -6.03014021e-04   2.08247527e-01\n",
      "   -1.02166203e-12   5.54870277e-13   4.12563816e-10  -5.34132004e-01\n",
      "   -6.13809049e-01   1.47079870e-01   5.69379270e-01  -5.71214199e-01\n",
      "    1.20339893e-11   3.36570472e-01  -6.19412184e-01  -5.29056072e-01\n",
      "   -6.09518349e-01   6.60591364e-01   5.37237942e-01   4.74100292e-01\n",
      "   -1.73863560e-01  -2.95982182e-01   4.98733193e-01  -4.80256468e-01\n",
      "   -4.49238752e-04  -2.95939539e-02  -1.38070805e-12   5.63016593e-01\n",
      "    7.15244412e-02   5.91280639e-01  -4.93317097e-02]\n",
      " [ -5.34472406e-01   6.94969416e-01   7.52047718e-01  -1.07960934e-02\n",
      "   -6.85127974e-01   7.08862126e-01  -6.09192312e-01  -5.97089350e-01\n",
      "    2.60722660e-03  -5.76405883e-01  -6.03841007e-01  -7.99028814e-01\n",
      "    5.65170944e-01  -1.02824962e+00   6.49461448e-01  -5.51660955e-01\n",
      "   -5.02643049e-01   6.20079160e-01  -4.89147961e-01   5.36046147e-01\n",
      "    6.99965239e-01  -4.58393753e-01  -5.65343201e-01  -6.47089899e-01\n",
      "   -5.02892435e-01  -7.17290878e-01   6.08831882e-01   5.66926062e-01\n",
      "   -5.13025105e-01   5.81704080e-01   5.32288432e-01  -5.28752446e-01\n",
      "   -7.01708972e-01   1.11924863e+00  -8.48752379e-01  -4.73735601e-01\n",
      "   -6.12700224e-01  -6.25399053e-01   5.64830124e-01  -2.16127131e-02\n",
      "    5.12062788e-01   6.67507887e-01   7.16487944e-01  -6.31198287e-01\n",
      "   -5.73120058e-01  -4.67186481e-01  -6.04722202e-01   5.40593326e-01\n",
      "    5.09575844e-01   5.94712377e-01  -5.99874258e-01   5.24874628e-01\n",
      "   -5.67468861e-03  -1.14864937e-03   5.68493426e-01  -6.35916770e-01\n",
      "   -6.51215494e-01   6.07825875e-01   6.60042822e-01  -6.65371656e-01\n",
      "   -4.53933716e-01   5.55566907e-01  -9.23390687e-01  -5.68511128e-01\n",
      "   -6.66673243e-01   6.90798163e-01   6.16344392e-01   5.57174325e-01\n",
      "   -6.51282907e-01  -5.73167384e-01   5.53892910e-01  -5.85093319e-01\n",
      "   -9.71565694e-02  -6.80474937e-01  -5.43167302e-03   6.52195215e-01\n",
      "    5.39951026e-01   6.20373428e-01  -5.50895452e-01]\n",
      " [ -3.79573435e-01   4.71706212e-01   4.07523483e-01  -3.73190519e-14\n",
      "   -5.47316551e-01   6.85741901e-01  -4.16517764e-07  -5.03075898e-01\n",
      "   -6.24303669e-13  -1.33745436e-06  -5.03666818e-01  -7.83122897e-01\n",
      "   -1.03768799e-11  -8.70638818e-04   6.02099836e-01  -5.94836473e-01\n",
      "   -1.41336268e-03   5.03126323e-01  -2.70529860e-03   1.96473350e-12\n",
      "    3.12141567e-01  -5.32863259e-01  -5.47474980e-01  -4.86472636e-01\n",
      "   -4.99759287e-01  -5.97569108e-01   6.17999196e-01   6.31391466e-01\n",
      "   -5.99594057e-01   3.37320002e-04   4.30259049e-01  -6.71213269e-01\n",
      "   -6.54509558e-09   3.96536618e-01  -8.54662061e-03  -5.06550789e-01\n",
      "   -5.36794543e-01  -6.49805009e-01   4.54349101e-01   8.57271409e-09\n",
      "    3.90126497e-01   7.27322847e-02   4.08009082e-01  -4.64111269e-01\n",
      "   -5.42941391e-01  -4.08881642e-02  -5.31449139e-01   3.86946380e-01\n",
      "    3.94820839e-01   1.12669230e-04  -6.05440757e-04   2.12372899e-01\n",
      "   -1.14832146e-12  -1.01773386e-12   3.79095505e-10  -4.65981871e-01\n",
      "   -6.23639643e-01   1.28945321e-01   6.00398004e-01  -5.81646562e-01\n",
      "    1.32827499e-11   3.40372145e-01  -6.14642024e-01  -6.11641109e-01\n",
      "   -6.80240512e-01   6.65861428e-01   6.13186955e-01   5.32564640e-01\n",
      "   -1.57740101e-01  -2.62432873e-01   5.13537943e-01  -4.92056936e-01\n",
      "   -5.04469965e-04  -3.21605317e-02  -8.51068348e-13   5.60278833e-01\n",
      "    7.28930682e-02   5.88792562e-01  -5.97774014e-02]]\n",
      " ===== printing paramter: W1_2 ===== \n",
      "[[ -8.40207458e-01   5.42414308e-01   7.29455531e-01 ...,   4.86211687e-01\n",
      "    5.14980078e-01  -4.28349525e-01]\n",
      " [ -6.64318264e-01   5.98324537e-01   6.69221401e-01 ...,   3.85269552e-01\n",
      "    6.06462240e-01  -5.52876592e-02]\n",
      " [ -6.09863043e-01   4.29291993e-01   7.17423081e-01 ...,   3.89806122e-01\n",
      "    4.39322442e-01  -2.42301509e-01]\n",
      " ..., \n",
      " [  4.68603021e-13  -9.02349376e-13   1.16789668e-11 ...,  -8.61783735e-12\n",
      "    4.44150716e-01  -4.16067354e-13]\n",
      " [ -4.81454581e-01   5.61587940e-13   1.83660880e-01 ...,   2.82164396e-11\n",
      "    1.33619830e-01  -5.00656049e-13]\n",
      " [ -7.80620813e-01   8.45171571e-01   7.51857400e-01 ...,   6.25223279e-01\n",
      "    6.41717732e-01  -6.03890121e-01]]\n",
      " ===== printing paramter: b1 ===== \n",
      "[[-0.48772961  0.46124318  0.84573394 -0.40578008 -0.31074983  0.92422926\n",
      "  -0.73839325 -0.41822302  0.66108268 -0.70918697 -0.58306056 -0.4230893\n",
      "   0.65343809 -1.55305028  0.66398281 -0.30671135 -0.38570333  0.82117623\n",
      "  -0.63998055  0.6252926   0.40626577 -0.41915423 -0.50892597 -0.53446615\n",
      "  -0.59013754 -0.69728196  0.39528251  0.51127857 -0.62712127  0.52822572\n",
      "   0.56954086 -0.47390944 -0.64554524  0.49179593 -0.82714242 -0.61766088\n",
      "  -0.69667935 -0.51697528  0.76515979 -1.00213301  0.32131484  0.41124699\n",
      "   0.48098165 -0.39591938 -0.63094199 -0.82021999 -0.78514588  0.59193331\n",
      "   0.37463722  0.45819649 -0.38289824  0.40487728 -0.28726366 -0.81212145\n",
      "   0.30719131 -0.78700548 -0.467655    0.5693987   0.49755043 -0.84164393\n",
      "  -0.74910349  0.81589127 -0.73693615 -0.68402195 -0.46772006  0.52207375\n",
      "   0.58554959  0.6976881  -0.74588555 -0.76114714  0.35576317 -0.59835458\n",
      "  -0.57443076 -0.77101672 -0.31607664  0.51978397  0.31814358  0.80395466\n",
      "  -0.34288362]]\n",
      " ===== printing paramter: W2_1 ===== \n",
      "[[  3.67059559e-01]\n",
      " [  3.40622775e-02]\n",
      " [  3.97171855e-01]\n",
      " [ -6.58652207e-05]\n",
      " [  2.45048502e-03]\n",
      " [  3.84548932e-01]\n",
      " [  1.98871456e-02]\n",
      " [  4.86627340e+00]\n",
      " [ -1.08716302e-12]\n",
      " [  8.48641144e-13]\n",
      " [  3.65001594e-13]\n",
      " [  6.74637212e-14]\n",
      " [  4.65596691e-13]\n",
      " [ -3.05065760e-14]\n",
      " [ -1.32481591e-12]\n",
      " [  9.83728615e-13]\n",
      " [  5.66633437e-13]\n",
      " [ -5.11086941e-13]\n",
      " [ -1.34999921e-12]\n",
      " [  6.31278233e-13]\n",
      " [  8.22535508e-13]\n",
      " [ -5.13221085e-13]\n",
      " [  3.61893187e-13]\n",
      " [  1.63839981e-12]\n",
      " [ -4.46611444e-13]\n",
      " [  1.01698706e-12]\n",
      " [ -6.09894080e-13]\n",
      " [ -5.00806102e-13]\n",
      " [  7.59797390e-13]\n",
      " [  6.78738478e-13]\n",
      " [  3.83717038e-13]\n",
      " [  1.49783647e-12]\n",
      " [ -7.92243278e-13]\n",
      " [  3.07338790e-14]\n",
      " [  7.39304505e-13]\n",
      " [  4.90328047e-13]\n",
      " [ -5.20250076e-14]\n",
      " [ -3.79752653e-13]\n",
      " [ -1.24058164e-12]\n",
      " [  4.61517109e-13]\n",
      " [  9.51417222e-14]\n",
      " [ -1.43152016e-12]\n",
      " [  6.01150585e-13]\n",
      " [  5.13585973e-13]\n",
      " [  9.22548713e-13]\n",
      " [  1.27708087e-12]\n",
      " [  6.25912516e-13]\n",
      " [  1.04533569e-12]\n",
      " [ -8.06336118e-13]\n",
      " [  1.15761643e-12]\n",
      " [  1.27756952e-12]\n",
      " [ -1.30425597e-12]\n",
      " [  4.48827309e-13]\n",
      " [  1.07527919e-12]\n",
      " [  2.07396358e-01]\n",
      " [  2.95549095e-01]\n",
      " [  1.18427753e-01]\n",
      " [ -1.20404035e-01]\n",
      " [ -2.37863511e-01]\n",
      " [  9.73699614e-02]\n",
      " [ -8.75275582e-05]]\n",
      " ===== printing paramter: W2_2 ===== \n",
      "[[ 0.58557039]\n",
      " [-0.07095111]\n",
      " [-0.1121124 ]\n",
      " [-0.25941229]\n",
      " [ 0.02163451]\n",
      " [ 0.18015154]\n",
      " [-0.48586944]\n",
      " [-1.19694054]\n",
      " [ 0.14557484]\n",
      " [ 0.27200043]\n",
      " [ 0.71548557]\n",
      " [ 0.38735729]\n",
      " [-1.02011442]\n",
      " [ 0.45301679]\n",
      " [ 1.45519197]\n",
      " [-0.60664493]\n",
      " [ 0.0601117 ]\n",
      " [-0.28891116]\n",
      " [-0.54552686]\n",
      " [-0.81241351]\n",
      " [-0.41027558]\n",
      " [-1.15092087]\n",
      " [ 0.2685101 ]\n",
      " [-0.82479763]\n",
      " [-0.89056617]\n",
      " [ 0.45912653]\n",
      " [-0.99053782]\n",
      " [-0.94487035]\n",
      " [ 0.65883887]\n",
      " [ 0.8586176 ]\n",
      " [-0.70109397]\n",
      " [-0.07680521]\n",
      " [ 0.61651611]\n",
      " [ 0.3218312 ]\n",
      " [ 0.52497673]\n",
      " [-1.17982709]\n",
      " [ 0.38157019]\n",
      " [ 1.02038848]\n",
      " [ 1.19627666]\n",
      " [ 0.61260003]\n",
      " [-0.31025293]\n",
      " [ 0.17201316]\n",
      " [-0.32694411]\n",
      " [ 1.21403098]\n",
      " [ 0.99737179]\n",
      " [-1.22458744]\n",
      " [ 1.12429082]\n",
      " [-0.39870733]\n",
      " [ 0.04178695]\n",
      " [ 1.20459211]\n",
      " [-0.22410567]\n",
      " [ 0.59393752]\n",
      " [ 0.98541844]\n",
      " [ 0.50750685]\n",
      " [ 0.6790117 ]\n",
      " [-0.91885149]\n",
      " [-0.79705417]\n",
      " [-0.36579758]\n",
      " [ 0.18509988]\n",
      " [ 1.2638514 ]\n",
      " [ 0.47770801]\n",
      " [ 0.74342787]\n",
      " [-0.52342552]\n",
      " [ 1.36274242]\n",
      " [-0.79006851]\n",
      " [-0.92822498]\n",
      " [-1.05798316]\n",
      " [-0.50168175]\n",
      " [-0.5674215 ]\n",
      " [ 0.02868575]\n",
      " [ 0.99673128]\n",
      " [-0.70682782]\n",
      " [ 0.58807498]\n",
      " [ 0.47857288]\n",
      " [-1.11566949]\n",
      " [-0.91927338]\n",
      " [ 0.91778892]\n",
      " [-0.52754986]\n",
      " [ 0.4101027 ]]\n",
      " ===== printing paramter: b2 ===== \n",
      "[[ 0.16055495]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=1500)\n",
    "import pickle\n",
    "para_names=['W1_1', 'W1_2', 'b1', 'W2_1', 'W2_2', 'b2']\n",
    "for i in range(len(para_names)):\n",
    "    print(' ===== printing paramter: '+ para_names[i] +' ===== ')\n",
    "    print(para_pred[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization nn for focal product price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simulation note:\n",
    "- ignored constant vector for the optimization, i.e. set as zero vector\n",
    "- only optimize over one focal product price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter:0, train_loss: 2.123753, test_loss: 1.705458\n",
      "simulated train_revenue: -2.123753, simulated test_revenue: -1.705458\n",
      "train D prediction parameters results: [-0.56634855]\n",
      "test D prediction parameters results: [-0.54230571]\n",
      "train p_f prediction parameters results: [-0.73945898]\n",
      "test p_f prediction parameters results: [-0.73945898]\n",
      "\n",
      "\n",
      "iter:100, train_loss: -1997.555664, test_loss: -1900.999023\n",
      "simulated train_revenue: 1997.555664, simulated test_revenue: 1900.999023\n",
      "train D prediction parameters results: [ 27.10195541]\n",
      "test D prediction parameters results: [ 25.08057594]\n",
      "train p_f prediction parameters results: [ 67.71386719]\n",
      "test p_f prediction parameters results: [ 67.71386719]\n",
      "\n",
      "\n",
      "iter:200, train_loss: -8167.280762, test_loss: -8148.831055\n",
      "simulated train_revenue: 8167.280762, simulated test_revenue: 8148.831055\n",
      "train D prediction parameters results: [ 54.85515213]\n",
      "test D prediction parameters results: [ 54.29496002]\n",
      "train p_f prediction parameters results: [ 148.170578]\n",
      "test p_f prediction parameters results: [ 148.170578]\n",
      "\n",
      "\n",
      "iter:300, train_loss: -19695.355469, test_loss: -19599.074219\n",
      "simulated train_revenue: 19695.355469, simulated test_revenue: 19599.074219\n",
      "train D prediction parameters results: [ 90.36256409]\n",
      "test D prediction parameters results: [ 84.60307312]\n",
      "train p_f prediction parameters results: [ 230.52207947]\n",
      "test p_f prediction parameters results: [ 230.52207947]\n",
      "\n",
      "\n",
      "iter:400, train_loss: -35743.382812, test_loss: -36082.078125\n",
      "simulated train_revenue: 35743.382812, simulated test_revenue: 36082.078125\n",
      "train D prediction parameters results: [ 114.50512695]\n",
      "test D prediction parameters results: [ 120.47376251]\n",
      "train p_f prediction parameters results: [ 312.56591797]\n",
      "test p_f prediction parameters results: [ 312.56591797]\n",
      "\n",
      "\n",
      " last test prediction parameters results: 492 55183.3 55384.5 \n",
      " predicted mean demand and price for one batch 142.879 [[ 387.63082886]]\n",
      "trained total elasped time: 3.4972965717315674\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "#optimize the loss funciton by adding negative sign\n",
    "start_time= time.time()\n",
    "tf.reset_default_graph()\n",
    "p_f = tf.get_variable('p_f', shape=(1, 1)) #corresponding index 0 in \n",
    "W1_1 = tf.constant(paras[0], dtype=tf.float32, name='W1_1' )\n",
    "W1_2_1 = tf.constant(paras[1][0, :], dtype=tf.float32, shape=[1, 79],name='W1_2_1')\n",
    "W1_2_2 = tf.constant(paras[1][1:, :], dtype=tf.float32, name='W1_2_2')\n",
    "b1 = tf.constant(paras[2], dtype=tf.float32, name='b1' )\n",
    "W2_1_1 = tf.constant(paras[3][0, :], dtype=tf.float32, shape=[1, 1],name='W1_2_1')\n",
    "W2_1_2 = tf.constant(paras[3][1:, :], dtype=tf.float32, name='W1_2_2')\n",
    "W2_2 = tf.constant(paras[4], dtype=tf.float32, name='W2_2' )\n",
    "b2 = tf.constant(paras[5], dtype=tf.float32, name='b2' )\n",
    "p_sub =  tf.placeholder(shape=(None, 18), dtype=tf.float32)\n",
    "p_t =  tf.placeholder(shape=(None, 60), dtype=tf.float32) #the other part except for the price\n",
    "\n",
    "D = tf.matmul(tf.nn.sigmoid(tf.matmul(p_f, W1_2_1)+ tf.matmul(p_t, W1_2_2) + tf.matmul(p_sub, W1_1)+b1), W2_2)+tf.matmul(p_f, W2_1_1)+ tf.matmul(p_t, W2_1_2)+b2\n",
    "    \n",
    "p_loss = tf.reduce_mean(-p_f*D) #self defined loss\n",
    "\n",
    "###parameters\n",
    "batch_size = 50\n",
    "learning_rate = 0.5\n",
    "trainer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "gradients = trainer.compute_gradients(p_loss)\n",
    "optimizer = trainer.apply_gradients(gradients)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(493):\n",
    "        #parameters \n",
    "        x1_train = tv_train.iloc[step:step+batch_size, 66:84].values \n",
    "        x1_test = tv_test.iloc[step:step+batch_size, 66:84].values\n",
    "        x2_train = np.concatenate((tv_train.iloc[step:step+batch_size, 4:11].values, tv_train.iloc[step:step+batch_size, 14:67].values), 1) \n",
    "        x2_test = np.concatenate((tv_test.iloc[step:step+batch_size, 4:11].values, tv_test.iloc[step:step+batch_size, 14:67].values), 1) \n",
    "\n",
    "        \n",
    "        loss_tr, _ = sess.run([p_loss, optimizer], feed_dict={p_sub: x1_train, p_t: x2_train})\n",
    "        _test_loss = sess.run([p_loss], feed_dict={p_sub: x1_test, p_t: x2_test})\n",
    "        \n",
    "        # predict\n",
    "        D_pred_tr = sess.run([D], feed_dict={p_sub:x1_train, p_t: x2_train})\n",
    "        D_pred_te = sess.run([D], feed_dict={p_sub:x1_test, p_t: x2_test})\n",
    "        pf_pred_tr = sess.run([p_f], feed_dict={p_sub:x1_train, p_t: x2_train})\n",
    "        pf_pred_te = sess.run([p_f], feed_dict={p_sub:x1_test, p_t: x2_test})\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print()\n",
    "            print(\"iter:%d, train_loss: %f, test_loss: %f\"%(step, loss_tr,  _test_loss[0]))\n",
    "            print(\"simulated train_revenue: %f, simulated test_revenue: %f\"%(-loss_tr,  -_test_loss[0]))\n",
    "            print('train D prediction parameters results:', D_pred_tr[0][0])\n",
    "            print('test D prediction parameters results:', D_pred_te[0][0])\n",
    "            print('train p_f prediction parameters results:', pf_pred_tr[0][0])\n",
    "            print('test p_f prediction parameters results:', pf_pred_te[0][0])\n",
    "            print()\n",
    "print('\\n last test prediction parameters results:', step, -loss_tr,  -_test_loss[0], \n",
    "    '\\n predicted mean demand and price for one batch', np.mean(D_pred_te[0]), pf_pred_te[0])\n",
    "\n",
    "end_time=time.time()\n",
    "print('trained total elasped time:', end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion on trained result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For optimize over one price, we got the optimized result of revenue 55384.5, corresponding predicted demand around 143 and price as 387.63. \n",
    "\n",
    "This method is proved to be fast, only took about 1 minute to train over the whole neural network, whicle flexible in terms of able to train on more prices only need to adjust the parameter setting for the second neural networ 'p_f, p_sub and p_t'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check focal product price manually;\n",
    "- Try to optimize over more price, other competitor prices in other columns (need to adjust columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
